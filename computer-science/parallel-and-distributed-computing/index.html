<!DOCTYPE html>
<html>
<head>
    

    

    



    <meta charset="utf-8">
    
    
    
    
    <title>并行计算 课程笔记 | 小灰灰灰灰的博客</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="theme-color" content="#3F51B5">
    
    
    <meta name="keywords" content="计算机科学,课程笔记,并行计算">
    <meta name="description" content="1 Introduction什么是并行计算 并行计算 (parallel computing)：在同一个计算机体系的多个处理器&#x2F;电脑一起工作解决一个问题 分布式计算 (distributed computing)：分布在多个计算机体系（异地）的处理器&#x2F;电脑一起工作解决一个问题 并行计算机 (parallel computer)：一个多核的计算机系统 并行计算机分为多计算机系统和中心化多处理器 多计">
<meta property="og:type" content="article">
<meta property="og:title" content="并行计算 课程笔记">
<meta property="og:url" content="https://blog.lyh543.cn/computer-science/parallel-and-distributed-computing/index.html">
<meta property="og:site_name" content="小灰灰灰灰的博客">
<meta property="og:description" content="1 Introduction什么是并行计算 并行计算 (parallel computing)：在同一个计算机体系的多个处理器&#x2F;电脑一起工作解决一个问题 分布式计算 (distributed computing)：分布在多个计算机体系（异地）的处理器&#x2F;电脑一起工作解决一个问题 并行计算机 (parallel computer)：一个多核的计算机系统 并行计算机分为多计算机系统和中心化多处理器 多计">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://blog.lyh543.cn/images/41c0ee131a061af3d800556179d029af72591aaedc55c8ea27e9de65d708f35e.png">
<meta property="og:image" content="https://blog.lyh543.cn/images/a7978bdb70dab368cd8bb46bcc422c604eee9caaa01740bbc643e67898c4c566.png">
<meta property="og:image" content="https://blog.lyh543.cn/images/65b9ee8cb161a9922d4ea87c47372cd33c7e3e8e174e1406b20ffa7d24a20786.png">
<meta property="og:image" content="https://blog.lyh543.cn/images/1bd8fa4ca6b97a525fc7df525d418279fb70e3bba08fd46a2c0bcf10b0c120c6.png">
<meta property="og:image" content="https://blog.lyh543.cn/images/b31c842db22a88cc5310ad83dfc800482945582e71cf6fff064d3ebb85e8b8bb.png">
<meta property="og:image" content="https://blog.lyh543.cn/images/b302fae7a7e7cede86e5fcac13f2f1a1fc688e04e5f29dbcb0e33c9b3bccec73.png">
<meta property="og:image" content="https://blog.lyh543.cn/images/ab410d9b708998ffb51f3aefd91effb7ca4b354f3d760f195c1777f0a985e5bf.png">
<meta property="og:image" content="https://blog.lyh543.cn/images/5474103543a1e0d0d127a9ed24803072a3fdf677114fb71fa7ad7bec245ee6da.png">
<meta property="og:image" content="https://blog.lyh543.cn/images/b65f17eaafed3888ffdcde84eb1ad84aeaa2ae1687221694405d9c3e95f57d35.png">
<meta property="og:image" content="https://blog.lyh543.cn/images/c1bb7fbb09828fa72ab8beb097f6e15ec05193210b10f5bc86a6e5e5b08ed1d1.png">
<meta property="og:image" content="https://blog.lyh543.cn/images/721e9e82756be134c4d86d06a1c54c0586d1c6b0dd82209f63b5674f24e07ec6.png">
<meta property="og:image" content="https://blog.lyh543.cn/images/3c4ac3aecb36f6b3c4d21e5dd1d9250b30fd54850fea0183b01b9de03169024e.png">
<meta property="og:image" content="https://blog.lyh543.cn/images/d2e14b80fbeca0d08d21fe3fdf5587d834a10f3ea523529ee3cf1765014c2e45.png">
<meta property="og:image" content="https://blog.lyh543.cn/images/0fb7fe40d8f55adf8f33169950b557a2106404164470c41751be8f754651da33.png">
<meta property="og:image" content="https://blog.lyh543.cn/images/d454a01f5f3d9d2e3792416ef7d268d42b8d85f0ad663a09d591cc9c584babc7.png">
<meta property="og:image" content="https://blog.lyh543.cn/images/bf0a0208fc6f11abc4703791e2338bb9a6dd02818f75764d4050b19e0d882b58.png">
<meta property="og:image" content="https://blog.lyh543.cn/images/252f55fa41156f6b15c36df9b59b46c0584bfa1af1e50f32a9507402d2f869de.png">
<meta property="og:image" content="https://blog.lyh543.cn/images/83e66b2afd4e1eddf9ef8e602988951cacccb828c479fef3facb01da8d8e2293.png">
<meta property="og:image" content="https://blog.lyh543.cn/images/a4680869e38463b763dd6a09111297235619f61afeda946b208a47cdd74005e9.png">
<meta property="og:image" content="https://blog.lyh543.cn/images/fcb65523957abd252aa1b01ab2c7c87d797a121a106ba9e64a1ff91ac8aaebbc.png">
<meta property="og:image" content="https://blog.lyh543.cn/images/807e384221a9eee87727e5c72b4e2397487d61877a61d664087eccc2f54b72a6.png">
<meta property="og:image" content="https://blog.lyh543.cn/images/88adda06e90b6e2c1c35fe8d2aad587701b90083324719108b918b9cc6902d4b.png">
<meta property="og:image" content="https://blog.lyh543.cn/images/4d969f0f01de0dbe26625734319141343aa94a3d757408bcdac3dab1d47851ae.png">
<meta property="og:image" content="https://blog.lyh543.cn/images/bd034b3575872b50830cff9eb155eda3ef522efb0552aed853a65cf98ee25494.png">
<meta property="og:image" content="https://blog.lyh543.cn/images/747c86c5ddb798561512cd64ff6699014e62dec235a4b397dad4b97e6dd7ccd9.png">
<meta property="og:image" content="https://blog.lyh543.cn/images/3468470bf9dc8be793b76a0e6cc744b6731b8c0d269058acd9c65a240b03f856.png">
<meta property="og:image" content="https://blog.lyh543.cn/images/c72afb5b5bac41c8bfcdb01a5fe8d35fc3fc79f5fa0b40f4643b66fcfa75fc3c.png">
<meta property="og:image" content="https://blog.lyh543.cn/images/79faaecb53a6c844f6ecccd9db9105a37912b1708a911b5d1c1179d1c0d7a8d7.png">
<meta property="og:image" content="https://blog.lyh543.cn/images/63f9b6471890380c4f186f2bd8b45e8e7b8d3e765ad9fb38ee2a2049736909bd.png">
<meta property="article:published_time" content="2021-03-02T02:41:36.000Z">
<meta property="article:modified_time" content="2021-09-11T12:19:35.087Z">
<meta property="article:author" content="lyh543">
<meta property="article:tag" content="计算机科学">
<meta property="article:tag" content="课程笔记">
<meta property="article:tag" content="并行计算">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://blog.lyh543.cn/images/41c0ee131a061af3d800556179d029af72591aaedc55c8ea27e9de65d708f35e.png">
    
        <link rel="alternate" type="application/atom+xml" title="小灰灰灰灰的博客" href="/atom.xml">
    
    <link rel="shortcut icon" href="/img/favicon.png">
    <link rel="stylesheet" href="/css/style.css?v=1.7.2">
    <script>window.lazyScripts=[]</script>

    <!-- custom head -->
    

<meta name="generator" content="Hexo 4.2.1"></head>

<body>
    <div id="loading" class="active"></div>

    <aside id="menu"  >
  <div class="inner flex-row-vertical">
    <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-off">
        <i class="mdi mdi-close icon-lg"></i>
    </a>
    <div class="brand-wrap" style="background-image:url(/img/brand.jpg)">
      <div class="brand">
        <a href="/" class="avatar waves-effect waves-circle waves-light">
          <img src="/img/avatar.png">
        </a>
        <hgroup class="introduce">
          <h5 class="nickname">lyh543</h5>
          <a href="mailto:lyh543@outlook.com" title="lyh543@outlook.com" class="mail">lyh543@outlook.com</a>
        </hgroup>
      </div>
    </div>
    <div class="scroll-wrap flex-col">
      <ul class="nav">
        
            <li class="waves-block waves-effect">
              <a href="/"  >
                <i class="icon icon-lg mdi mdi-home"></i>
                主页
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/archives"  >
                <i class="icon icon-lg mdi mdi-archive"></i>
                归档
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/tags"  >
                <i class="icon icon-lg mdi mdi-tag-multiple"></i>
                标签
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/categories"  >
                <i class="icon icon-lg mdi mdi-format-list-bulleted-square"></i>
                分类
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="https://github.com/lyh543" target="_blank" >
                <i class="icon icon-lg mdi mdi-github"></i>
                Github
              </a>
            </li>
        
      </ul>
    </div>
  </div>
</aside>

    <main id="main">
        <header class="top-header" id="header">
    <div class="flex-row">
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle">
          <i class="icon icon-lg mdi mdi-menu"></i>
        </a>
        <div class="flex-col header-title ellipsis">并行计算 课程笔记</div>
        
        <div class="search-wrap" id="search-wrap">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
                <i class="icon icon-lg mdi mdi-chevron-left"></i>
            </a>
            <input type="text" id="key" class="search-input" autocomplete="off" placeholder="输入感兴趣的关键字">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="search">
                <i class="icon icon-lg mdi mdi-magnify"></i>
            </a>
        </div>
        
        
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menuShare">
            <i class="icon icon-lg mdi mdi-share-variant"></i>
        </a>
        
    </div>
</header>
<header class="content-header post-header">

    <div class="container fade-scale">
        <h1 class="title">并行计算 课程笔记</h1>
        <h5 class="subtitle">
            
                <time datetime="2021-03-02T02:41:36.000Z" itemprop="datePublished" class="page-time">
  2021-03-02
</time>


	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/">计算机科学</a></li></ul>

            
        </h5>
    </div>

    


</header>


<div class="container body-wrap">
    
    <aside class="post-widget">
        <nav class="post-toc-wrap post-toc-shrink" id="post-toc">
            <h4>TOC</h4>
            <ol class="post-toc"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#1-Introduction"><span class="post-toc-text">1 Introduction</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#什么是并行计算"><span class="post-toc-text">什么是并行计算</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#为什么需要并行计算"><span class="post-toc-text">为什么需要并行计算</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#并行计算关心的问题"><span class="post-toc-text">并行计算关心的问题</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#如何编写并行程序"><span class="post-toc-text">如何编写并行程序</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#举个栗子"><span class="post-toc-text">举个栗子</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#并行程序的编写方向"><span class="post-toc-text">并行程序的编写方向</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#习题"><span class="post-toc-text">习题</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#2-Parallel-Programming-Platform"><span class="post-toc-text">2 Parallel Programming Platform</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#对冯诺依曼体系的改进"><span class="post-toc-text">对冯诺依曼体系的改进</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#缓存"><span class="post-toc-text">缓存</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#缓存的写策略"><span class="post-toc-text">缓存的写策略</span></a></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#缓存的映射方法"><span class="post-toc-text">缓存的映射方法</span></a></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#缓存优化的技巧"><span class="post-toc-text">缓存优化的技巧</span></a></li></ol></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#虚拟内存"><span class="post-toc-text">虚拟内存</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#指令级并行"><span class="post-toc-text">指令级并行</span></a></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#线程级并行"><span class="post-toc-text">线程级并行</span></a></li></ol></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#并行计算的硬件"><span class="post-toc-text">并行计算的硬件</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#MIMD-物理组织"><span class="post-toc-text">MIMD 物理组织</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#共享内存系统"><span class="post-toc-text">共享内存系统</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#互连网络"><span class="post-toc-text">互连网络</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#多维-Mesh-网络"><span class="post-toc-text">多维 Mesh 网络</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#超立方体结构"><span class="post-toc-text">超立方体结构</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#缓存一致性"><span class="post-toc-text">缓存一致性</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#写失效协议"><span class="post-toc-text">写失效协议</span></a></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#基于目录的缓存一致性协议"><span class="post-toc-text">基于目录的缓存一致性协议</span></a></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#False-Sharing"><span class="post-toc-text">False Sharing</span></a></li></ol></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#并行计算的软件"><span class="post-toc-text">并行计算的软件</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#输入输出"><span class="post-toc-text">输入输出</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#3-Parallel-Program-Design"><span class="post-toc-text">3 Parallel Program Design</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Foster-四步走"><span class="post-toc-text">Foster 四步走</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#分块"><span class="post-toc-text">分块</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#通信"><span class="post-toc-text">通信</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#聚合"><span class="post-toc-text">聚合</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#映射"><span class="post-toc-text">映射</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#4-Performance"><span class="post-toc-text">4 Performance</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#加速比和效率指标"><span class="post-toc-text">加速比和效率指标</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Amdahl-定律"><span class="post-toc-text">Amdahl 定律</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Gustafson-Barsis-定律"><span class="post-toc-text">Gustafson-Barsis 定律</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Karp-Flatt-Metric-指标"><span class="post-toc-text">Karp-Flatt Metric 指标</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#等效率"><span class="post-toc-text">等效率</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#可扩展性"><span class="post-toc-text">可扩展性</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#5-Message-Passing-Programming"><span class="post-toc-text">5 Message-Passing Programming</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#附-MPICH-中文教程"><span class="post-toc-text">附 MPICH 中文教程</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#6-The-Sieve-of-Eratosthenes"><span class="post-toc-text">6 The Sieve of Eratosthenes</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#分块算法"><span class="post-toc-text">分块算法</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#算法性能分析"><span class="post-toc-text">算法性能分析</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#7-Floyd’s-Algorithm"><span class="post-toc-text">7 Floyd’s Algorithm</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#分块-1"><span class="post-toc-text">分块</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#通信-1"><span class="post-toc-text">通信</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#聚合和映射"><span class="post-toc-text">聚合和映射</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#点对点通信"><span class="post-toc-text">点对点通信</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#死锁"><span class="post-toc-text">死锁</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Ssend"><span class="post-toc-text">Ssend</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#SendRecv"><span class="post-toc-text">SendRecv</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#并行-Floyd-算法"><span class="post-toc-text">并行 Floyd 算法</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#CUDA-部分"><span class="post-toc-text">CUDA 部分</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#结构"><span class="post-toc-text">结构</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#代码思路"><span class="post-toc-text">代码思路</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Block-大小"><span class="post-toc-text">Block 大小</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#CGMA"><span class="post-toc-text">CGMA</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Shared-Memory-And-Threading"><span class="post-toc-text">Shared Memory And Threading</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#OpenACC-部分"><span class="post-toc-text">OpenACC 部分</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#GPU-占用率"><span class="post-toc-text">GPU 占用率</span></a></li></ol></li></ol>
        </nav>
    </aside>


<article id="post-computer-science/parallel-and-distributed-computing"
  class="post-article article-type-post fade" itemprop="blogPost">

    <div class="post-card">
        <h1 class="post-card-title">并行计算 课程笔记</h1>
        <div class="post-meta">
            <time class="post-time" title="2021-03-02 10:41:36" datetime="2021-03-02T02:41:36.000Z"  itemprop="datePublished">2021-03-02</time>

            
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/">计算机科学</a></li></ul>



            

        </div>
        <div class="post-content" id="post-content" itemprop="postContent">
            <h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h2><h3 id="什么是并行计算"><a href="#什么是并行计算" class="headerlink" title="什么是并行计算"></a>什么是并行计算</h3><ul>
<li>并行计算 (parallel computing)：在<strong>同一个</strong>计算机体系的多个处理器/电脑一起工作解决一个问题</li>
<li>分布式计算 (distributed computing)：分布在<strong>多个</strong>计算机体系（异地）的处理器/电脑一起工作解决一个问题</li>
<li>并行计算机 (parallel computer)：一个多核的计算机系统<ul>
<li>并行计算机分为多计算机系统和中心化多处理器</li>
<li>多计算机系统 (multicomputer)：多个计算机通过<strong>内部网络</strong>连接</li>
<li>中心化多处理器 (centralized/symmetrical multiprocessor, SMP)：一个计算机系统，其中所有 CPU 共享一个全局<strong>内存</strong></li>
</ul>
</li>
</ul>
<p>并行计算多用于科学计算，分布式计算多用于可靠性、可用性、性价比高的计算。</p>
<h3 id="为什么需要并行计算"><a href="#为什么需要并行计算" class="headerlink" title="为什么需要并行计算"></a>为什么需要并行计算</h3><ul>
<li>微处理器性能增长越来越慢</li>
<li>同样的性能下，并行系统功耗更低</li>
</ul>
<h3 id="并行计算关心的问题"><a href="#并行计算关心的问题" class="headerlink" title="并行计算关心的问题"></a>并行计算关心的问题</h3><p>不懂的地方都给出英文原文……</p>
<ul>
<li>架构上的问题：<ul>
<li>Pipline, ILP…</li>
<li>缓存一致性</li>
<li>单共享总线 or 网络</li>
<li>UMA, NUMA, CC-NUMA, Cluster…</li>
</ul>
</li>
<li>编程模型上的问题：<ul>
<li>单寻址空间 or 多寻址空间</li>
<li>进程使用锁、消息传递 or 其他方法进行同步</li>
<li>分布式 or 中心化内存</li>
<li>故障可靠性</li>
</ul>
</li>
<li>性能表现上的问题：<ul>
<li>指标：规模、加速比、可扩展性</li>
<li>Models: PRAM，BSP，PPRAM…</li>
<li>并行计算的评价方法</li>
</ul>
</li>
<li>其他问题：<ul>
<li>编程语言</li>
<li>编程工具</li>
<li>可移植性</li>
<li>Automatic programming of parallel computers</li>
<li>Education of parallel computing philosophy</li>
</ul>
</li>
</ul>
<h3 id="如何编写并行程序"><a href="#如何编写并行程序" class="headerlink" title="如何编写并行程序"></a>如何编写并行程序</h3><ul>
<li>需要明确告诉不同处理器如何分工</li>
<li>需要把串行程序改写为并行</li>
<li>有时候直接改写的效率非常低，需要设计全新的算法</li>
</ul>
<h4 id="举个栗子"><a href="#举个栗子" class="headerlink" title="举个栗子"></a>举个栗子</h4><p>例子：求 n 个函数值的和，其串行算法如下：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sum = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; n; i++)</span><br><span class="line">&#123;</span><br><span class="line">    x = compute_next_value(...);</span><br><span class="line">    sum += x;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>假设我们有 p 个核 (p &lt; n)，每个核计算一部分：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">my_sum = <span class="number">0</span>;</span><br><span class="line">my_first_i = ...;</span><br><span class="line">my_last_i = ...;</span><br><span class="line"><span class="keyword">for</span> (my_i = my_first_i; my_i &lt; my_last_i; my_i++)</span><br><span class="line">&#123;</span><br><span class="line">    my_x = compute_next_value(...);</span><br><span class="line">    my_sum += my_x;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>计算后的结果存在私有变量 <code>my_sum</code> 中。</p>
<p>所有核计算完成后，他们将结果发送至班长（一般就设 0 号核为班长），班长负责计算最终的总和。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (I am the master core) &#123;</span><br><span class="line">    sum = my_x;</span><br><span class="line">    <span class="keyword">for</span> each core other than myself &#123;</span><br><span class="line">        receive value from core;</span><br><span class="line">        sum += value;</span><br><span class="line">    &#125;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    send my_x to the master;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<hr>
<p>更好的并行策略是，不要让班长核做所有的合并工作，而是均摊高每个核上。</p>
<p>对于这个问题，可以两两组合：</p>
<blockquote>
<p>Work with odd and even numbered pairs of cores. Pair the cores so that core 0 adds its result with core 1’s result，Core 2 adds its result with core 3’s result, etc.<br>Repeat the process now with only the evenly ranked cores. Core 0 adds result from core 2. Core 4 adds the result from core 6, etc.<br>Now cores divisible by 4 repeat the process, and so forth, until core 0 has the final result.</p>
</blockquote>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="../../images/41c0ee131a061af3d800556179d029af72591aaedc55c8ea27e9de65d708f35e.png" alt="两两组合的求和算法" title="">
                </div>
                <div class="image-caption">两两组合的求和算法</div>
            </figure>

<p>这种算法中，班长只进行了 3 次通信 + 3 次求和，相较刚开始的 7 次通信 + 3 次求和。如果核数更多，这样优化的效果会更加显著。</p>
<p>但是，越复杂的问题，并行的难度会更大（比如翻译程序）。所以我们需要编写并行程序来提高多核的利用率。</p>
<h4 id="并行程序的编写方向"><a href="#并行程序的编写方向" class="headerlink" title="并行程序的编写方向"></a>并行程序的编写方向</h4><ol>
<li>任务并行：将整个任务分成很多不同的小任务</li>
<li>数据并行：将数据进行分块，每个核在自己分到的数据上做相似的任务</li>
</ol>
<hr>
<p>例子：3 个老师（A、B、C）批改 300 张试卷，每张试卷 15 题。</p>
<ul>
<li>任务并行（将试卷按题目进行划分）：A 老师批改 1-5 题，B 老师批改 6-10 题，C 老师批改 11-15 题</li>
<li>数据并行（将试卷按张数进行划分）：每位老师各批改 100 张试卷</li>
</ul>
<h3 id="习题"><a href="#习题" class="headerlink" title="习题"></a>习题</h3><p>在求和的栗子中，设计一个分配任务的函数（该函数负责计算每个核的 <code>my_first_i</code> 和 <code>my_last_i</code>），使得 $n$ 个任务尽量均匀地分布在 $p$ 个核上。</p>
<p>（这个题目后面应该会讲）</p>
<p>一个优秀的算法是：</p>
<p>$$my\_first\_i = \lfloor\frac{i*n}{p}\rfloor\\<br>my\_last\_i = \lfloor\frac{(i+1)*n}{p}\rfloor - 1<br>$$</p>
<p>其中 $i$ 为当前核的下标，从 0 开始。</p>
<p><code>my_last_i</code> 比较好理解，因为任务分配是连续的，<code>my_last_i</code> 就是 下一个核的 <code>my_first_i</code> 减 1。</p>
<p>至于 <code>my_first_i</code> 的由来我也没想清楚，但是它可以保证<strong>所有任务的数量差不超过 1</strong>，很均匀。</p>
<p>各位不妨写一个程序模拟一下分配情况，看看每个在不同的 <code>n</code>、<code>p</code> 下，每个核被分了多少个任务、规律是怎么样的。如，在 <code>n=30</code>，<code>p=9</code> 时，该算法会这样分配：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">3 3 4 3 3 4 3 3 4</span><br></pre></td></tr></table></figure>

<h2 id="2-Parallel-Programming-Platform"><a href="#2-Parallel-Programming-Platform" class="headerlink" title="2 Parallel Programming Platform"></a>2 Parallel Programming Platform</h2><h3 id="对冯诺依曼体系的改进"><a href="#对冯诺依曼体系的改进" class="headerlink" title="对冯诺依曼体系的改进"></a>对冯诺依曼体系的改进</h3><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="../../images/a7978bdb70dab368cd8bb46bcc422c604eee9caaa01740bbc643e67898c4c566.png" alt="冯诺依曼体系" title="">
                </div>
                <div class="image-caption">冯诺依曼体系</div>
            </figure>

<p>冯诺依曼的核心是：存储程序，顺序执行。</p>
<p>该体系的瓶颈一般是 CPU 和内存分离。</p>
<p>改进分为三个方向：</p>
<ol>
<li>缓存</li>
<li>虚拟存储</li>
<li>底层的并行（指令集并行、线程级并行）</li>
</ol>
<h4 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h4><p>缓存：比主存更快的存储。一版用户存放物理上接近、且经常使用的数据和指令。</p>
<p>局部性原理略。</p>
<p>缓存分为 3 级。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="../../images/65b9ee8cb161a9922d4ea87c47372cd33c7e3e8e174e1406b20ffa7d24a20786.png" alt="3 级缓存" title="">
                </div>
                <div class="image-caption">3 级缓存</div>
            </figure>

<p>Cache 命中（Cache hit）和不命中（Cache miss）</p>
<h5 id="缓存的写策略"><a href="#缓存的写策略" class="headerlink" title="缓存的写策略"></a>缓存的写策略</h5><p>当 CPU 更新缓存的数据时，缓存数据可能会和主存不同。此时有两种策略：</p>
<ol>
<li>Write-through（写直达）：更新缓存的同时更新主存；缓存和主存始终一致，但每次写缓存的速度会变慢。</li>
<li>Write-back（写回）：更新缓存时标记缓存为<strong>脏数据（dirty）</strong>，当该行缓存被替换时，脏数据会被写回至主存；写缓存的速度不受影响，但缓存替换时的速度会变慢。</li>
</ol>
<h5 id="缓存的映射方法"><a href="#缓存的映射方法" class="headerlink" title="缓存的映射方法"></a>缓存的映射方法</h5><ol>
<li>全映射：每行内存可以映射在缓存的任意位置</li>
<li>直接映射：每行内存只能映射在缓存的固定位置（一般是内存行数下标 % 缓存总行数）</li>
<li>n 路组相联映射：将缓存每 n 行分为一组，每行内存可以映射在缓存的固定的组的 n 行中任意一行（一般组号 = 内存行数下标 % 缓存总行数 % n）</li>
</ol>
<p>使用全映射或 n 路组相联映射，还需要考虑替换策略，常见的可以使用 LRU。</p>
<h5 id="缓存优化的技巧"><a href="#缓存优化的技巧" class="headerlink" title="缓存优化的技巧"></a>缓存优化的技巧</h5><p>缓存对于应用程序和程序员是透明的（不能直接控制缓存），但如果知道局部性原理，可以通过改变程序顺序、间接控制缓存，进而优化速度。</p>
<ol>
<li>合并数组（data merge）：通过将两个独立数组合并为一个复合元素的数组来改进空间局部性</li>
<li>循环交换（loop interchange）：通过改变循环嵌套来按序访问存储器中存储的数据</li>
<li>循环合并（loop fusion）：将两个具有相同循环类型且有一些变量重叠的独立循环合并</li>
<li>块化（blocking）：通过不断使用一些数据块（而不是完整地遍历一行和一列）来改进时间局部性</li>
</ol>
<hr>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="../../images/1bd8fa4ca6b97a525fc7df525d418279fb70e3bba08fd46a2c0bcf10b0c120c6.png" alt="循环优化前后的代码" title="">
                </div>
                <div class="image-caption">循环优化前后的代码</div>
            </figure>

<p>假设缓存大小为 4。第一种循环会发生 4 次缓存未命中、第二种循环会发生 16 次缓存未命中。（注：缓存的机制是，每次缓存不命中会将所在行的 4 个元素全部装进缓存）</p>
<h4 id="虚拟内存"><a href="#虚拟内存" class="headerlink" title="虚拟内存"></a>虚拟内存</h4><p>虚拟内存的大小大于主存，会将不活跃的程序换到磁盘，活跃的程序放到主存，加快速度。</p>
<h5 id="指令级并行"><a href="#指令级并行" class="headerlink" title="指令级并行"></a>指令级并行</h5><ol>
<li>流水线技术，参考计算机系统结构</li>
<li>某些情况下，多条指令也可以被同时发射</li>
<li>分支预测</li>
</ol>
<h5 id="线程级并行"><a href="#线程级并行" class="headerlink" title="线程级并行"></a>线程级并行</h5><p>略。</p>
<h3 id="并行计算的硬件"><a href="#并行计算的硬件" class="headerlink" title="并行计算的硬件"></a>并行计算的硬件</h3><ol>
<li>SISD（传统冯诺依曼模型）</li>
<li>SIMD：对多个数据进行相同操作，1 个控制单元 + 多个 ALU</li>
<li>MISD（尚未开发）</li>
<li>MIMD：使用多个指令流同时操作多个数据流，多个独立操作单元 + 各自的 ALU</li>
</ol>
<h4 id="MIMD-物理组织"><a href="#MIMD-物理组织" class="headerlink" title="MIMD 物理组织"></a>MIMD 物理组织</h4><p>从上到下越来越离散：</p>
<ol>
<li>共享缓存架构（Shared Cache Architecture），多为单芯片多处理器</li>
</ol>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="../../images/b31c842db22a88cc5310ad83dfc800482945582e71cf6fff064d3ebb85e8b8bb.png" alt="共享缓存架构" title="">
                </div>
                <div class="image-caption">共享缓存架构</div>
            </figure>

<ol start="2">
<li>统一内存寻址（Uniform Memory Access，UMA）</li>
</ol>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="../../images/b302fae7a7e7cede86e5fcac13f2f1a1fc688e04e5f29dbcb0e33c9b3bccec73.png" alt="统一内存寻址（UMA）" title="">
                </div>
                <div class="image-caption">统一内存寻址（UMA）</div>
            </figure>

<ol start="3">
<li>独立内存寻址（Non-Uniform Memory Access，NUMA）</li>
</ol>
<p>NUMA 并不是处理器完全不能访问其他块的内存，而是处理器可以直接访问一部分内存+通过处理器内置的特殊硬件访问其他内存。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="../../images/ab410d9b708998ffb51f3aefd91effb7ca4b354f3d760f195c1777f0a985e5bf.png" alt="独立内存寻址（NUMA）" title="">
                </div>
                <div class="image-caption">独立内存寻址（NUMA）</div>
            </figure> 

<ol start="4">
<li>分布式系统/内存、集群（Distributed System/Memory）</li>
</ol>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="../../images/5474103543a1e0d0d127a9ed24803072a3fdf677114fb71fa7ad7bec245ee6da.png" alt="分布式系统/内存" title="">
                </div>
                <div class="image-caption">分布式系统/内存</div>
            </figure>

<h4 id="共享内存系统"><a href="#共享内存系统" class="headerlink" title="共享内存系统"></a>共享内存系统</h4><p>略。</p>
<h4 id="互连网络"><a href="#互连网络" class="headerlink" title="互连网络"></a>互连网络</h4><p>网络的类型、网络的性能指标的一堆概念略。</p>
<h4 id="多维-Mesh-网络"><a href="#多维-Mesh-网络" class="headerlink" title="多维 Mesh 网络"></a>多维 Mesh 网络</h4><p>Mesh：将一维线性的网络拓展到二维、三维或更高维度，结点之间只能和邻居进行交流。</p>
<h4 id="超立方体结构"><a href="#超立方体结构" class="headerlink" title="超立方体结构"></a>超立方体结构</h4><p>超立方体结构：$d$ 维的超立方体有 $p=2^d$ 个结点。</p>
<p>对超立方体进行编号，可以按照如图的规律：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="../../images/b65f17eaafed3888ffdcde84eb1ad84aeaa2ae1687221694405d9c3e95f57d35.png" alt="三维及以下的超立方体" title="">
                </div>
                <div class="image-caption">三维及以下的超立方体</div>
            </figure>

<p>每个 $d$ 维的超立方体可以分成两个相同的 $d-1$ 维超立方体，编号分别以 0 和 1 开头，且两个子超立方体对应结点的编号除第一位外相同。</p>
<p>按此法可以构造出四维超立方体。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="../../images/c1bb7fbb09828fa72ab8beb097f6e15ec05193210b10f5bc86a6e5e5b08ed1d1.png" alt="四维超立方体" title="">
                </div>
                <div class="image-caption">四维超立方体</div>
            </figure>

<p>该编号方案还有一个性质：两个结点的距离等于这两个结点的汉明距离（不同的位的数量）。如在图中，0110 和 0101 的距离为 2。该性质在使用超立方体构造并行算法时会很有用。</p>
<h4 id="缓存一致性"><a href="#缓存一致性" class="headerlink" title="缓存一致性"></a>缓存一致性</h4><p>缓存的写策略有 Write-back 和 Write-through。在 UMA 架构下，多个处理器有各自的缓存，共用内存。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="../../../images/721e9e82756be134c4d86d06a1c54c0586d1c6b0dd82209f63b5674f24e07ec6.png" alt="UMA 架构下的缓存一致性协议" title="">
                </div>
                <div class="image-caption">UMA 架构下的缓存一致性协议</div>
            </figure>

<p>于是，出现了两个新的概念：</p>
<ul>
<li>Write Invalidate：处理器写自己的缓存时，使其他缓存失效；Write-through 下还需要更新内存，Write-back 下需要使内存失效。</li>
<li>Write Update：处理器写自己的缓存时，立即更新其他缓存；Write-through 下还需要更新内存，Write-back 下需要标记缓存为脏，在缓存失效的时候写回内存。</li>
</ul>
<p>两种策略在什么情况下性能更好？（猜测是在不同核频繁更新不同数据时，写失效更好；多个核都在频繁写同一个数据时，写更新更好。）</p>
<p>现代计算机都默认使用写失效策略。（猜测是因为局部性原理，多核读不同数据的情况更多）</p>
<h5 id="写失效协议"><a href="#写失效协议" class="headerlink" title="写失效协议"></a>写失效协议</h5><p>三种状态：<strong>Shared</strong>、<strong>Invalid</strong>、<strong>Modified</strong>（MSI）</p>
<ul>
<li><code>Shared</code>：存在多份有效的数据（写会导致其他失效）</li>
<li><code>Modified</code>：只有当前数据有效（写不会导致其他失效）</li>
<li><code>Invalidate</code>：数据无效（读会请求数据）</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="../../../images/3c4ac3aecb36f6b3c4d21e5dd1d9250b30fd54850fea0183b01b9de03169024e.png" alt="三状态转换图" title="">
                </div>
                <div class="image-caption">三状态转换图</div>
            </figure>

<hr>
<p>硬件条件：所有核共享一个总线，可以用于广播。当 0 号处理器更新了 <code>x</code>，会广波这个消息，其他核听到（snoop）以后就会把自己的 <code>x</code> 标记为 <code>Invalid</code>。</p>
<hr>
<ol>
<li>当一个数据是 <code>Modified</code> 后，所有操作都直接在本地进行，无需向外部广播。</li>
<li>多个核读入一个数据时，所有缓存的内容都会变为 <code>Shared</code>，随后所有的读操作都直接在本地进行，无需向外部广播。</li>
<li>多个核同时读和写时，会出现（在带宽上的）瓶颈</li>
</ol>
<h5 id="基于目录的缓存一致性协议"><a href="#基于目录的缓存一致性协议" class="headerlink" title="基于目录的缓存一致性协议"></a>基于目录的缓存一致性协议</h5><ul>
<li>基于目录：共享的状态都存储在（位于内存的）“目录”</li>
<li>目录里用一位表示 shared/dirty 状态（State）</li>
<li>目录里用一个 bitmap 表示数据被缓存在哪些处理器（Presence Bits）</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="../../../images/d2e14b80fbeca0d08d21fe3fdf5587d834a10f3ea523529ee3cf1765014c2e45.png" alt="目录" title="">
                </div>
                <div class="image-caption">目录</div>
            </figure>

<ol>
<li>处理器 0 和处理器 1 读 x，此时状态为 shared，0 和 1 的 presence bits 均为 1</li>
<li>处理器 0 写变量，状态变为 dirty，1 的 presence bits 为 0</li>
<li>处理器 2 读变量，将会请求处理器 0 写回，随后 0 和 2 的 presence bits 均为 1</li>
</ol>
<hr>
<p>该方案的开销主要是通信开销、以及可能出现频繁的争端。</p>
<p>如果一个并行程序需要大量的一致性操作（大量的读/写共享数据块），目录最终会限制它的并行性能。</p>
<hr>
<p>还可以分布式的目录系统，但是这里就学了。</p>
<h5 id="False-Sharing"><a href="#False-Sharing" class="headerlink" title="False Sharing"></a>False Sharing</h5><p>不懂</p>
<h3 id="并行计算的软件"><a href="#并行计算的软件" class="headerlink" title="并行计算的软件"></a>并行计算的软件</h3><p>并行软件也有区别：</p>
<ul>
<li>内存共享系统上，一个进程 fork 出多个线程</li>
<li>分布式系统上，需要多个进程</li>
</ul>
<p>SPMD: single program multiple data，MPI 和 CUDA 都是用的都是这种。</p>
<p>解决并行软件的不一致性：给数据加锁</p>
<p>SPMD 的写法：</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">char message [ <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> ] ;</span><br><span class="line">. . .</span><br><span class="line">my_rank = Get_rank ( ) ;</span><br><span class="line">if ( my_rank == <span class="number">1</span>) &#123;</span><br><span class="line">     sprintf ( message , <span class="string">"Greetings from process 1"</span> ) ;</span><br><span class="line">     Send ( message , MSG_CHAR , <span class="number">100</span> , <span class="number">0</span> ) ;</span><br><span class="line">&#125; else if ( my_rank == <span class="number">0</span>) &#123;</span><br><span class="line">     Receive ( message , MSG_CHAR , <span class="number">100</span> , <span class="number">1</span> ) ;</span><br><span class="line">     printf ( <span class="string">"Process 0 &gt; Received: %s<span class="subst">\n</span>"</span> , message ) ;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="输入输出"><a href="#输入输出" class="headerlink" title="输入输出"></a>输入输出</h3><p>Google 翻译 yyds</p>
<p>当我们的并行程序需要进行 I/O 时，做出这些假设并遵循这些规则：<br>在分布式内存程序中，仅进程0将访问stdin。 在共享内存程序中，只有主线程或线程 0 会访问 stdin。<br>在分布式内存和共享内存程序中，所有进程/线程都可以访问 stdout 和 stderr。<br>然而，由于输出到 stdout 的顺序不确定，在大多数情况下，除了调试输出之外，只有一个进程/线程将用于所有输出到 stdout。<br>调试输出应始终包括生成输出的进程/线程的等级或 ID。<br>只有单个进程/线程会尝试访问除 stdin、stdout 或 stderr 之外的任何单个文件。 因此，例如，每个进程/线程都可以打开自己的私有文件进行读取或写入，但没有两个进程/线程会打开同一个文件。</p>
<h2 id="3-Parallel-Program-Design"><a href="#3-Parallel-Program-Design" class="headerlink" title="3 Parallel Program Design"></a>3 Parallel Program Design</h2><h3 id="Foster-四步走"><a href="#Foster-四步走" class="headerlink" title="Foster 四步走"></a>Foster 四步走</h3><p>注意这四步，是设计算法的过程的四步，而不是并行算法的先后步骤。</p>
<ul>
<li>Partitioning：分块</li>
<li>Communication：通信</li>
<li>Agglomeration：组合</li>
<li>Mapping：映射</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="../../../images/0fb7fe40d8f55adf8f33169950b557a2106404164470c41751be8f754651da33.png" alt="Foster’s Design Methodology" title="">
                </div>
                <div class="image-caption">Foster’s Design Methodology</div>
            </figure>

<h3 id="分块"><a href="#分块" class="headerlink" title="分块"></a>分块</h3><p>Domain vs. Functional Decomposition</p>
<p>其实就是数据并行 vs. 任务并行</p>
<h3 id="通信"><a href="#通信" class="headerlink" title="通信"></a>通信</h3><p>通信方法可以分为局部通信和邻居通信</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="../../images/d454a01f5f3d9d2e3792416ef7d268d42b8d85f0ad663a09d591cc9c584babc7.png" alt="Local communication" title="">
                </div>
                <div class="image-caption">Local communication</div>
            </figure>

<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="../../images/bf0a0208fc6f11abc4703791e2338bb9a6dd02818f75764d4050b19e0d882b58.png" alt="Global communication" title="">
                </div>
                <div class="image-caption">Global communication</div>
            </figure>

<hr>
<p>例子：对求和问题进行分治，只需要 logN 步</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="../../images/252f55fa41156f6b15c36df9b59b46c0584bfa1af1e50f32a9507402d2f869de.png" alt="分治求和问题" title="">
                </div>
                <div class="image-caption">分治求和问题</div>
            </figure>

<hr>
<p>通信方法也可以分为结构化通信（通信网络有一定结构）和非结构化通信（通信网络可能是任意图）。</p>
<p>如果通信网络还在变化，负载均衡算法就必须频繁地更新。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="../../images/83e66b2afd4e1eddf9ef8e602988951cacccb828c479fef3facb01da8d8e2293.png" alt="Unstructured communication" title="">
                </div>
                <div class="image-caption">Unstructured communication</div>
            </figure>

<h3 id="聚合"><a href="#聚合" class="headerlink" title="聚合"></a>聚合</h3><p>聚合可以减少通信成本：任务的通信需求与其操作的子域的表面成正比，而计算需求与子域的体积成正比。有时我们可以权衡复制计算以减少通信需求和/或执行时间。</p>
<h3 id="映射"><a href="#映射" class="headerlink" title="映射"></a>映射</h3><p>映射：将任务映射到处理器上。</p>
<p>目标：最大化处理器利用（即负载均衡） &amp; 最小化处理器间通信（即需要通信的进程可以映射到同一处理器）</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="../../images/a4680869e38463b763dd6a09111297235619f61afeda946b208a47cdd74005e9.png" alt="奇奇怪怪的图的一种映射方法" title="">
                </div>
                <div class="image-caption">奇奇怪怪的图的一种映射方法</div>
            </figure>

<p>不同情况下映射策略：略。</p>
<hr>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="../../images/fcb65523957abd252aa1b01ab2c7c87d797a121a106ba9e64a1ff91ac8aaebbc.png" alt="Agglomeration 例题" title="">
                </div>
                <div class="image-caption">Agglomeration 例题</div>
            </figure>

<p>公式：</p>
<ul>
<li>$\chi$：更新一个元素的时间</li>
<li>$\lambda$：一个元素通信的时间</li>
<li>$n$：结点数</li>
<li>$m$：需要的迭代次数</li>
<li>$p$：处理器数</li>
</ul>
<p>有一下结论：</p>
<ul>
<li>串行执行时间：$m(n-1)\chi$</li>
<li>并行执行时间：$m\lceil(n-1)/p\rceil+2\lambda$</li>
</ul>
<p>有点不懂。是在这个问题下的时间公式吗？</p>
<h2 id="4-Performance"><a href="#4-Performance" class="headerlink" title="4 Performance"></a>4 Performance</h2><p>性能指标：运行时间、加速比、效率、可扩展性等</p>
<h3 id="加速比和效率指标"><a href="#加速比和效率指标" class="headerlink" title="加速比和效率指标"></a>加速比和效率指标</h3><p>$$S_p = \frac{T_s}{T_p}$$</p>
<ul>
<li>$T_s$：串行时间</li>
<li>$T_p$：$p$ 个进程时的并行时间（按最长时间的进程计算）</li>
<li>$S_p$ or $\psi(n, p)$：$p$ 个进程时的加速比 (Speedup)</li>
</ul>
<p><strong>加速比是速度的正比，是时间的反比</strong></p>
<p>$$\psi(n, p) \leq \frac{\sigma(n)+\varphi(n)}{\sigma(n)+\varphi(n) / p+\kappa(n, p)}$$</p>
<p>好的加速比：（相较进程数）线性加速、亚线性加速、超线性加速</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/images/807e384221a9eee87727e5c72b4e2397487d61877a61d664087eccc2f54b72a6.png" alt="好的加速比" title="">
                </div>
                <div class="image-caption">好的加速比</div>
            </figure>

<p>超线性加速出现在：多级内存、缓存影响、DFS 遍历树算法等。</p>
<hr>
<p>$$\psi(n, p) \leq \frac{\sigma(n)+\varphi(n)}{\sigma(n)+\varphi(n) / p+\kappa(n, p)}$$</p>
<ul>
<li>$\sigma(n)$：不能被并行执行的的串行时间</li>
<li>$\varphi(n)$：可以被并行执行的串行时间</li>
<li>$\kappa(n, p)$：并行执行带来的通信时间</li>
</ul>
<p>比较显然，公式的意思是：并行算法的时间为：<code>串行时间+并行部分/p+通行时间</code></p>
<p><strong>这个公式一定要记住，后面的推导都是基于这个公式！</strong></p>
<hr>
<p>$$E_p=\frac{S_p}{p}$$</p>
<ul>
<li>$E_p$ or $\varepsilon(n, p)$：效率</li>
</ul>
<p>线性加速比程序的效率为 100%。</p>
<p>将 $S_p$ 代入即有：</p>
<p>$$\varepsilon(n, p) \leq \frac{\sigma(n)+\varphi(n)}{p\sigma(n)+\varphi(n)+p\kappa(n, p)}$$</p>
<p>可以推出 $0 \leq \varepsilon(n, p) \leq 1$。</p>
<h4 id="Amdahl-定律"><a href="#Amdahl-定律" class="headerlink" title="Amdahl 定律"></a>Amdahl 定律</h4><p>Amdahl 定律和 Gustafson-Barsis 定律都把通信成本放缩掉了。两个求的都是加速比，但是注意条件不一样（一个是 $f$ 一个是 $s$）</p>
<p>$$\psi(n, p) \leq \frac{\sigma(n)+\varphi(n)}{\sigma(n)+\varphi(n) / p+\kappa(n, p)}$$</p>
<p>令 $f$ 为串行部分占比（占改进之前的比），即 $f=\frac{\sigma(n)}{\sigma(n)+\varphi(n)}$，有：</p>
<p>$$\psi \leq \frac{1}{f+(1-f)/p}$$</p>
<p><strong>加速比不大于“串行占比+p倍并行占比”的反比</strong></p>
<hr>
<blockquote>
<p>例题：95% of a program’s execution time occurs inside a loop that can be executed in parallel. What is the maximum speedup we should expect from a parallel version of the program executing on 8 CPUs?</p>
</blockquote>
<p>注意题目说的是串行在改进前需要执行 5% 的时间，这就符合 Amdahl 的条件。答案是 5.9。</p>
<h4 id="Gustafson-Barsis-定律"><a href="#Gustafson-Barsis-定律" class="headerlink" title="Gustafson-Barsis 定律"></a>Gustafson-Barsis 定律</h4><p>令 $s$ 为串行部分占比（占改进之后的比），即 $s = \frac{\sigma(n)}{\sigma(n)+\varphi(n)/p}$，有：</p>
<p>$$\psi \leq p + (1-p)s$$</p>
<p>可以看到，如果 $s$ 小，$\psi \approx p$，并行效率很好。</p>
<hr>
<blockquote>
<p>例题：An application running on 10 processors spends 3% of its time in serial code. What is the scaled speedup of the application?</p>
</blockquote>
<p>注意题目说的是串行代码在改进后需要执行 3% 的时间，这就符合 Gustafson-Barsis 的条件。答案是 9.73。</p>
<h4 id="Karp-Flatt-Metric-指标"><a href="#Karp-Flatt-Metric-指标" class="headerlink" title="Karp-Flatt Metric 指标"></a>Karp-Flatt Metric 指标</h4><p>Amdahl 和 Gustafson-Barsis 都忽略了通信成本，会高估放大比。Karp-Flatt 从另一个角度来进行分析。</p>
<p>但是这个公式起手就很怪异。</p>
<p>令$e = \frac{\sigma(n) + \kappa(n,p)}{\sigma(n)+\varphi(n)}$</p>
<p><code>串行时间 + 通信时间 / 串行时间 + 可并行的时间</code>？</p>
<p>能够推出</p>
<p>$$e = \frac{1/\psi - 1/p}{1 - 1/p}$$</p>
<hr>
<p>这个公式很奇怪，结合例题我大概看懂了：</p>
<p>结论 1：注意到 $n$ 一定的情况下，<code>串行时间</code>、<code>可并行的时间</code> 是恒定的，所以 <strong>$e$ 和 <code>通信时间</code> 的增长趋势是一样的</strong>。<br>即，<strong>在不同的 $p$ 下，如果 $e$ 恒定，说明通信时间恒定；$e$ 稳定增长，说明通信时间也稳定增长。</strong></p>
<p>结论 2：随 $p$ 的增大，$e$ 不能先增大后减小（只能一直增大/不变或一直减小/不变：一直增大是次线性加速比，而一直减小就是超线性加速比）</p>
<hr>
<p>例 1：</p>
<table>
<thead>
<tr>
<th>$p$</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
<th>7</th>
<th>8</th>
</tr>
</thead>
<tbody><tr>
<td>$\psi$</td>
<td>1.8</td>
<td>2.5</td>
<td>3.1</td>
<td>3.6</td>
<td>4.0</td>
<td>4.4</td>
<td>4.7</td>
</tr>
<tr>
<td>计算可得 $e$</td>
<td>0.1</td>
<td>0.1</td>
<td>0.1</td>
<td>0.1</td>
<td>0.1</td>
<td>0.1</td>
<td>0.1</td>
</tr>
</tbody></table>
<p>为什么 8 核的加速比只有 4.7？注意到 $e$ 不随 $p$ 变化，说明问题不是通信成本，是串行代码耗时太高。</p>
<hr>
<p>例 2：</p>
<table>
<thead>
<tr>
<th>$p$</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
<th>7</th>
<th>8</th>
</tr>
</thead>
<tbody><tr>
<td>$\psi$</td>
<td>1.9</td>
<td>2.6</td>
<td>3.2</td>
<td>3.7</td>
<td>4.1</td>
<td>4.5</td>
<td>4.7</td>
</tr>
<tr>
<td>计算可得 $e$</td>
<td>0.07</td>
<td>0.075</td>
<td>0.08</td>
<td>0.085</td>
<td>0.09</td>
<td>0.095</td>
<td>0.1</td>
</tr>
</tbody></table>
<p>为什么 8 核的加速比只有 4.7？注意到 $e$ 不随 $p$ 变化，说明问题不是通信成本，是串行代码耗时太高。</p>
<hr>
<p>例 3：</p>
<table>
<thead>
<tr>
<th>$p$</th>
<th>4</th>
<th>8</th>
<th>12</th>
</tr>
</thead>
<tbody><tr>
<td>$\psi$</td>
<td>3.9</td>
<td>6.5</td>
<td>？</td>
</tr>
</tbody></table>
<p><code>?</code> 处能否为 10？</p>
<p>假设 <code>?=10</code>，算得 $e$ 先增大后减小，不可能。</p>
<h3 id="等效率"><a href="#等效率" class="headerlink" title="等效率"></a>等效率</h3><p>不会，看 PPT</p>
<h3 id="可扩展性"><a href="#可扩展性" class="headerlink" title="可扩展性"></a>可扩展性</h3><p>不会，看 PPT</p>
<h2 id="5-Message-Passing-Programming"><a href="#5-Message-Passing-Programming" class="headerlink" title="5 Message-Passing Programming"></a>5 Message-Passing Programming</h2><p>MPI 常用函数</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//First MPI function called by each process</span></span><br><span class="line">MPI_Init (&amp;argc, &amp;argv);</span><br><span class="line"></span><br><span class="line"><span class="comment">// First argument is communicator</span></span><br><span class="line"><span class="comment">// Number of processes returned through second argument</span></span><br><span class="line">MPI_Comm_size (MPI_COMM_WORLD, &amp;p);</span><br><span class="line"><span class="comment">// Process rank (in range 0, 1, …, p-1) returned through second argument</span></span><br><span class="line">MPI_Comm_rank (MPI_COMM_WORLD, &amp;id);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Call after all other MPI library calls</span></span><br><span class="line">MPI_Finalize();</span><br></pre></td></tr></table></figure>

<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// reduce 操作</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Reduce</span> <span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span> *operand,      <span class="comment">/* addr of 1st reduction element */</span></span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span> *result,       <span class="comment">/* addr of 1st reduction result, only root get result */</span></span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> count,          <span class="comment">/* reductions to perform */</span></span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Datatype type,  <span class="comment">/* type of elements */</span></span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Op <span class="keyword">operator</span>,    <span class="comment">/* reduction operator */</span></span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> root,           <span class="comment">/* process getting result(s) */</span></span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Comm comm       <span class="comment">/* communicator */</span></span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span></span><br><span class="line"><span class="function"><span class="title">MPI_Reduce</span> <span class="params">(&amp;count, &amp;global_count, MPI_INT, <span class="number">0</span>, MPI_COMM_WORLD)</span></span>;</span><br></pre></td></tr></table></figure>

<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Benchmarking the Program</span></span><br><span class="line"><span class="keyword">double</span> elapsed_time;</span><br><span class="line">MPI_Init (&amp;argc, &amp;argv);</span><br><span class="line">MPI_Barrier (MPI_COMM_WORLD);</span><br><span class="line">elapsed_time = - MPI_Wtime();</span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line">MPI_Reduce (…);</span><br><span class="line">elapsed_time += MPI_Wtime();</span><br></pre></td></tr></table></figure>

<h3 id="附-MPICH-中文教程"><a href="#附-MPICH-中文教程" class="headerlink" title="附 MPICH 中文教程"></a>附 MPICH 中文教程</h3><p><a href="https://scc.ustc.edu.cn/zlsc/cxyy/200910/MPICH/" target="_blank" rel="noopener">https://scc.ustc.edu.cn/zlsc/cxyy/200910/MPICH/</a></p>
<h2 id="6-The-Sieve-of-Eratosthenes"><a href="#6-The-Sieve-of-Eratosthenes" class="headerlink" title="6 The Sieve of Eratosthenes"></a>6 The Sieve of Eratosthenes</h2><p>因为这部分做了实验，所以不多说算法原理了。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Bcast</span> <span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span> *buffer,           <span class="comment">/* Addr of 1st element */</span></span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> count,              <span class="comment">/* # elements to broadcast */</span></span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Datatype datatype,  <span class="comment">/* Type of elements */</span></span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> root,               <span class="comment">/* ID of root process */</span></span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Comm comm)</span>          <span class="comment">/* Communicator */</span></span></span><br><span class="line"><span class="function"><span class="title">MPI_Bcast</span> <span class="params">(&amp;k, <span class="number">1</span>, MPI_INT, <span class="number">0</span>, MPI_COMM_WORLD)</span></span>;</span><br></pre></td></tr></table></figure>

<h3 id="分块算法"><a href="#分块算法" class="headerlink" title="分块算法"></a>分块算法</h3><p>这个问题需要按数据分块。可以使用循环分配，可以按块分配。</p>
<p>使用循环分配，</p>
<p>$$my\_first\_i = i * \lfloor\frac{n}{p}\rfloor + \min(i,r)\\<br>my\_last\_i = (i+1)* \lfloor\frac{n}{p}\rfloor + \min(i+1,r) - 1 \\<br>count= \min(\lfloor \frac{j}{\lfloor n / p \rfloor+1}\rfloor, \lfloor \frac{j-r}{\lfloor n / p \rfloor}\rfloor)<br>$$</p>
<p>使用按块分配，就是第一章的<a href="#%E4%B9%A0%E9%A2%98">习题</a>中提到的：</p>
<p>$$my\_first\_i = \lfloor\frac{i*n}{p}\rfloor\\<br>my\_last\_i = \lfloor\frac{(i+1)*n}{p}\rfloor - 1 \\<br>count=\lfloor \frac{p(j+1)-1}{n}\rfloor<br>$$</p>
<p>两种算法都可以，后面一种表达式更简单，所以选择这一种。</p>
<h3 id="算法性能分析"><a href="#算法性能分析" class="headerlink" title="算法性能分析"></a>算法性能分析</h3><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="../../images/88adda06e90b6e2c1c35fe8d2aad587701b90083324719108b918b9cc6902d4b.png" alt="时间复杂度" title="">
                </div>
                <div class="image-caption">时间复杂度</div>
            </figure>

<h2 id="7-Floyd’s-Algorithm"><a href="#7-Floyd’s-Algorithm" class="headerlink" title="7 Floyd’s Algorithm"></a>7 Floyd’s Algorithm</h2><p>Floyd 算法伪代码：</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> k = <span class="number">0</span> to n<span class="number">-1</span></span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">0</span> to n<span class="number">-1</span></span><br><span class="line">        <span class="keyword">for</span> <span class="built_in">j</span> = <span class="number">0</span> to n<span class="number">-1</span></span><br><span class="line">            a[<span class="built_in">i</span>,<span class="built_in">j</span>] = <span class="built_in">min</span> (a[<span class="built_in">i</span>,<span class="built_in">j</span>], a[<span class="built_in">i</span>,k] + a[k,<span class="built_in">j</span>])</span><br><span class="line">        endfor</span><br><span class="line">    endfor</span><br><span class="line">endfor</span><br></pre></td></tr></table></figure>

<h3 id="分块-1"><a href="#分块-1" class="headerlink" title="分块"></a>分块</h3><p>把矩阵 A 的每个元素视为一个任务，分解成 $n^2$ 个任务。</p>
<h3 id="通信-1"><a href="#通信-1" class="headerlink" title="通信"></a>通信</h3><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="../../images/4d969f0f01de0dbe26625734319141343aa94a3d757408bcdac3dab1d47851ae.png" alt="通信" title="">
                </div>
                <div class="image-caption">通信</div>
            </figure>

<h3 id="聚合和映射"><a href="#聚合和映射" class="headerlink" title="聚合和映射"></a>聚合和映射</h3><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="../../images/bd034b3575872b50830cff9eb155eda3ef522efb0552aed853a65cf98ee25494.png" alt="按行或者按列聚合" title="">
                </div>
                <div class="image-caption">按行或者按列聚合</div>
            </figure>

<p>按行或者按列聚合。最后选择按行聚合，在读文件的时候会容易的多。</p>
<h3 id="点对点通信"><a href="#点对点通信" class="headerlink" title="点对点通信"></a>点对点通信</h3><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="../../images/747c86c5ddb798561512cd64ff6699014e62dec235a4b397dad4b97e6dd7ccd9.png" alt="点对点通信" title="">
                </div>
                <div class="image-caption">点对点通信</div>
            </figure>

<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Send</span> <span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span>         *message,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span>           count,</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Datatype  datatype,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span>           dest,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span>           tag,</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Comm      comm</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Recv</span> <span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span>         *message,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span>           count,</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Datatype  datatype,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span>           source,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span>           tag,</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Comm      comm,</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Status   *status</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span></span><br></pre></td></tr></table></figure>

<p>Send 和 Recv 需要约定相同的 tag，以及对方的 id (作为自己的 source/dest)。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="../../images/3468470bf9dc8be793b76a0e6cc744b6731b8c0d269058acd9c65a240b03f856.png" alt="send/recv 原理" title="">
                </div>
                <div class="image-caption">send/recv 原理</div>
            </figure>

<ul>
<li><code>MPI_Send</code> 函数会一直阻塞直至 message_buffer 空了。</li>
<li><code>MPI_Recv</code> 函数会一直阻塞直至收到消息。</li>
</ul>
<p>这就很容易造成死锁。</p>
<h4 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (id == <span class="number">0</span>) &#123;</span><br><span class="line">    MPI_Recv (&amp;b,...);</span><br><span class="line">    MPI_Send (&amp;a,...);</span><br><span class="line">   c = (a + b)/<span class="number">2.0</span>; </span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (id == <span class="number">1</span>) &#123;</span><br><span class="line">    MPI_Recv (&amp;a,...);</span><br><span class="line">    MPI_Send (&amp;b,...);</span><br><span class="line">   c = (a + b)/<span class="number">2.0</span>; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Process 0 blocks waiting for message from 1, but 1 blocks waiting for a message from 0.<br>Deadlock!</p>
<hr>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (id ==<span class="number">0</span>) &#123;</span><br><span class="line">    MPI_Send(&amp;a, ... <span class="number">1</span>,MPI_COMM_WORLD);</span><br><span class="line">    MPI_Recv(&amp;b, ... <span class="number">1</span>, MPI_COMM_WORLD,&amp;status);</span><br><span class="line">    c = (a+b)/<span class="number">2.0</span>; </span><br><span class="line">&#125;<span class="keyword">else</span> <span class="keyword">if</span> (id ==<span class="number">1</span>) &#123;</span><br><span class="line">    MPI_Send(&amp;a, ... <span class="number">0</span>,MPI_COMM_WORLD);</span><br><span class="line">    MPI_Recv(&amp;b, ... <span class="number">0</span>, MPI_COMM_WORLD,&amp;status);</span><br><span class="line">    c = (a+b)/<span class="number">2.0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Both processes send before they try to receive, but they still deadlock.  Why?<br>The tags are wrong. Process 0 is trying to receive a tag of 1, but Process 1 is sending a tag of 0.</p>
<h4 id="Ssend"><a href="#Ssend" class="headerlink" title="Ssend"></a>Ssend</h4><p>依赖 buffer 的 <code>MPI_send</code> 是不安全的，因为 MPI 标准允许 <code>MPI_Send</code> 可以提供/不提供 buffer。</p>
<p>两种问题可能会出问题：</p>
<ol>
<li>双方都是先发后收，并且发的数据都很大</li>
<li>生产者/消费者问题，且生产者生产的比消费者块</li>
</ol>
<p>MPI 标准定义了 <code>MPI_Ssend</code>，保证发送会被阻塞（<code>s</code> 表 <code>synchronous</code>）。</p>
<h4 id="SendRecv"><a href="#SendRecv" class="headerlink" title="SendRecv"></a>SendRecv</h4><p>如果需要同时发送接收，可以通过代码逻辑使大家按照某种顺序，避免死锁，但也可以使用 <code>MPI_SendRecv</code> 同时发送和接收，中间的调度由 MPI 实现。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="../../images/c72afb5b5bac41c8bfcdb01a5fe8d35fc3fc79f5fa0b40f4643b66fcfa75fc3c.png" alt="MPI_SendRecv" title="">
                </div>
                <div class="image-caption">MPI_SendRecv</div>
            </figure>

<h3 id="并行-Floyd-算法"><a href="#并行-Floyd-算法" class="headerlink" title="并行 Floyd 算法"></a>并行 Floyd 算法</h3><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="../../images/79faaecb53a6c844f6ecccd9db9105a37912b1708a911b5d1c1179d1c0d7a8d7.png" alt="核心部分" title="">
                </div>
                <div class="image-caption">核心部分</div>
            </figure>

<ul>
<li>计算时间复杂度：$\Theta(n^3/p)$</li>
<li>通信时间复杂度：$n^2 \log p$</li>
<li>执行时间（其中 $\beta$ 是显存带宽，其他变量见第三章）：</li>
</ul>
<p>$$n \lceil n / p \rceil n \chi +<br>n \lceil \log p \rceil (\lambda + 4n / \beta)$$</p>
<h2 id="CUDA-部分"><a href="#CUDA-部分" class="headerlink" title="CUDA 部分"></a>CUDA 部分</h2><h3 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h3><ul>
<li>Thread – Register</li>
<li>Warp</li>
<li>Block – 对应一个 Streming Multiprocessors，Shared Memory</li>
<li>Grid – 对应一个 Kernel</li>
<li>Device – Global Memory</li>
</ul>
<h3 id="代码思路"><a href="#代码思路" class="headerlink" title="代码思路"></a>代码思路</h3><p>用  Block 处理二维图像：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="keyword">void</span> <span class="title">PictureKernel</span><span class="params">(<span class="keyword">float</span>* d_Pin, <span class="keyword">float</span>* d_Pout, <span class="keyword">int</span> height, <span class="keyword">int</span> width)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">int</span> Row = blockIdx.y*blockDim.y + threadIdx.y;</span><br><span class="line">  <span class="keyword">int</span> Col = blockIdx.x*blockDim.x + threadIdx.x;</span><br><span class="line">  <span class="keyword">if</span> ((Row &lt; height) &amp;&amp; (Col &lt; width)) &#123;</span><br><span class="line">    d_Pout[Row*width+Col] = <span class="number">2.0</span>*d_Pin[Row*width+Col];</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="function">dim3 <span class="title">DimGrid</span><span class="params">((n<span class="number">-1</span>)/<span class="number">16</span> + <span class="number">1</span>, (m<span class="number">-1</span>)/<span class="number">16</span>+<span class="number">1</span>, <span class="number">1</span>)</span></span>;</span><br><span class="line">  <span class="function">dim3 <span class="title">DimBlock</span><span class="params">(<span class="number">16</span>, <span class="number">16</span>, <span class="number">1</span>)</span></span>;</span><br><span class="line">  PictureKernel&lt;&lt;&lt;DimGrid,DimBlock&gt;&gt;&gt;(d_Pin, d_Pout, m, n);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Block-大小"><a href="#Block-大小" class="headerlink" title="Block 大小"></a>Block 大小</h3><p>For Matrix Multiplication using multiple blocks, should I use 8X8, 16X16 or 32X32 blocks for Fermi?</p>
<ul>
<li>For 8X8, we have 64 threads per Block. Since each SM can take up to 1536 threads, which translates to 24 Blocks. However, each SM can only take up to 8 Blocks, only 512 threads will go into each SM!</li>
<li>For 16X16, we have 256 threads per Block. Since each SM can take up to 1536 threads, it can take up to 6 Blocks and achieve full capacity unless other resource considerations overrule.</li>
<li>For 32X32, we would have 1024 threads per Block. Only one block can fit into an SM for Fermi. Using only 2/3 of the thread capacity of an SM. </li>
</ul>
<h3 id="CGMA"><a href="#CGMA" class="headerlink" title="CGMA"></a>CGMA</h3><p>CGMA = 从全局内存中取一个数，多少次运算用到了这个数</p>
<p>CGMA 越大越好</p>
<h3 id="Shared-Memory-And-Threading"><a href="#Shared-Memory-And-Threading" class="headerlink" title="Shared Memory And Threading"></a>Shared Memory And Threading</h3><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="../../images/63f9b6471890380c4f186f2bd8b45e8e7b8d3e765ad9fb38ee2a2049736909bd.png" alt="Shared Memory And Threading" title="">
                </div>
                <div class="image-caption">Shared Memory And Threading</div>
            </figure>

<h2 id="OpenACC-部分"><a href="#OpenACC-部分" class="headerlink" title="OpenACC 部分"></a>OpenACC 部分</h2><h3 id="GPU-占用率"><a href="#GPU-占用率" class="headerlink" title="GPU 占用率"></a>GPU 占用率</h3><blockquote>
<p>GPU Occupancy is:</p>
<ul>
<li>How much parallelism is running / How much parallelism the hardware could run</li>
<li>100% occupancy is not required for, nor does it guarantee best performance.</li>
<li>Less than 50% occupancy is often a red flag</li>
</ul>
</blockquote>

        </div>

        <blockquote class="post-copyright">
    
    <div class="content">
        
<span class="post-time">
    最后更新时间：<time datetime="2021-09-11T12:19:35.087Z" itemprop="dateUpdated">2021-09-11 20:19:35</time>
</span><br>


        
    </div>
    
    <footer>
        <a href="https://blog.lyh543.cn">
            <img src="/img/avatar.png" alt="lyh543">
            lyh543
        </a>
    </footer>
</blockquote>

        


        <div class="post-footer">
            
	<ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/" rel="tag">并行计算</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/" rel="tag">计算机科学</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/" rel="tag">课程笔记</a></li></ul>


            
<div class="page-share-wrap">
    

<div class="page-share" id="pageShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=https://blog.lyh543.cn/computer-science/parallel-and-distributed-computing/&title=《并行计算 课程笔记》 — 小灰灰灰灰的博客&pic=https://blog.lyh543.cn/img/avatar.png" data-title="微博">
          <i class="icon mdi mdi-sina-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=https://blog.lyh543.cn/computer-science/parallel-and-distributed-computing/&title=《并行计算 课程笔记》 — 小灰灰灰灰的博客&source=" data-title=" QQ">
          <i class="icon mdi mdi-qqchat"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=https://blog.lyh543.cn/computer-science/parallel-and-distributed-computing/" data-title=" Facebook">
          <i class="icon mdi mdi-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《并行计算 课程笔记》 — 小灰灰灰灰的博客&url=https://blog.lyh543.cn/computer-science/parallel-and-distributed-computing/&via=https://blog.lyh543.cn" data-title=" Twitter">
          <i class="icon mdi mdi-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=https://blog.lyh543.cn/computer-science/parallel-and-distributed-computing/" data-title=" Google+">
          <i class="icon mdi mdi-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>



    <a href="javascript:;" id="shareFab" class="page-share-fab waves-effect waves-circle">
        <i class="icon icon-lg mdi mdi-share-variant"></i>
    </a>
</div>



        </div>
    </div>

    
<nav class="post-nav flex-row flex-justify-between">
  
    <div class="waves-block waves-effect prev">
      <a href="/computer-science/compile-principle/" id="post-prev" class="post-nav-link">
        <div class="tips"><i class="icon mdi mdi-chevron-left icon-lg icon-pr"></i> Prev</div>
        <h4 class="title">编译原理 课程笔记</h4>
      </a>
    </div>
  

  
    <div class="waves-block waves-effect next">
      <a href="/computer-science/computer-architecture/" id="post-next" class="post-nav-link">
        <div class="tips">Next <i class="icon icon-lg icon-pl mdi mdi-chevron-right"></i></div>
        <h4 class="title">计算机系统结构 复习笔记</h4>
      </a>
    </div>
  
</nav>



    

















<section class="comments" id="comments">
    <div id="gitalk-container"></div>
    <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
    <script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
    <script>
        var id = location.pathname
        if (location.pathname.length > 50) {
          id = location.pathname.replace(/\/\d+\/\d+\/\d+\//, '').replace('/', '').substring(0, 50)
        }
        const gitalk = new Gitalk({
          clientID: 'ec7daa4e047c3c30570d',
          clientSecret: '025a9e40a1d101f28fd1a945d286a819e9fa1c3d',
          repo: 'lyh543.github.io',
          owner: 'lyh543',
          admin: ['lyh543'],
          id: id,      // Ensure uniqueness and length less than 50
          title: document.title.split('|')[0],
          distractionFreeMode: false  // Facebook-like distraction free mode
        })

        gitalk.render('gitalk-container')
    </script>
</section>




</article>



</div>

        <footer class="footer">
    <div class="top">
        

        <p>
            
                <span><a href="/atom.xml" target="_blank" class="rss" title="rss"><i class="icon icon-lg mdi mdi-rss"></i></a></span>
            
            <span>博客内容遵循 <a rel="license noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank">知识共享 署名 - 非商业性 - 相同方式共享 4.0 国际协议</a></span>
        </p>
    </div>
    <div class="bottom">
        <p><span>lyh543 &copy; 2019 - 2021</span>
            <span>
                
                <a href="http://www.miitbeian.gov.cn/" target="_blank">蜀ICP备19034464号</a><br>
                
                Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> Theme <a href="https://github.com/yscoder/hexo-theme-indigo" target="_blank">indigo</a>
            </span>
        </p>
    </div>
</footer>

    </main>
    <div class="mask" id="mask"></div>
<a href="javascript:;" id="gotop" class="waves-effect waves-circle waves-light"><span class="icon icon-lg mdi mdi-chevron-up"></span></a>



<div class="global-share" id="globalShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=https://blog.lyh543.cn/computer-science/parallel-and-distributed-computing/&title=《并行计算 课程笔记》 — 小灰灰灰灰的博客&pic=https://blog.lyh543.cn/img/avatar.png" data-title="微博">
          <i class="icon mdi mdi-sina-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=https://blog.lyh543.cn/computer-science/parallel-and-distributed-computing/&title=《并行计算 课程笔记》 — 小灰灰灰灰的博客&source=" data-title=" QQ">
          <i class="icon mdi mdi-qqchat"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=https://blog.lyh543.cn/computer-science/parallel-and-distributed-computing/" data-title=" Facebook">
          <i class="icon mdi mdi-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《并行计算 课程笔记》 — 小灰灰灰灰的博客&url=https://blog.lyh543.cn/computer-science/parallel-and-distributed-computing/&via=https://blog.lyh543.cn" data-title=" Twitter">
          <i class="icon mdi mdi-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=https://blog.lyh543.cn/computer-science/parallel-and-distributed-computing/" data-title=" Google+">
          <i class="icon mdi mdi-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>


<div class="page-modal wx-share" id="wxShare">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <p>扫一扫，分享到微信</p>
    <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAN4AAADeCAAAAAB3DOFrAAACrElEQVR42u3awY4iMQwEUP7/p2evK+0CVXaCGOn1Cc1Adx6H2JTzeMTXz1/Xs7+8/uyz17P/Hr7w8PDwFkv/93r9nmcPfo2f3T95/3+eiIeHh3eNl2/oOenNg8s9PCkSeHh4eN/JyzflvF1Ono6Hh4f3e3nJZ/P75+UHDw8P79t4m7hhE1skn9oUJzw8PLwbvHyK9D2vr8z38PDw8NZT9bZIJPdPFpoUoWi1eHh4eBd4baCQt7ntSGwTiLxZJx4eHt4FXvuDf9OUJ3HD7OhVFC7j4eHhrXmvF92WgU0znbOLth4PDw/vAm//4z95fFtU8qMGyVeDh4eHd5aXt8un2t88aGjX82irDR4eHt6Cl7xuo9hZbNEWmGi+h4eHh3eN1w668hBh1hDPRl9FNcPDw8Nb8PJAtm3Nk0Z59mVFK8TDw8O7wNuPoNqtvw1286Y/GoPh4eHhrXn7wwFJYdhs8QcOXeHh4eFd4LVhbn6Uqi057SjuzRrw8PDwrvFmTfPm7wkvP5rw5tAVHh4e3lHeLJBNmuyc0RaAVaSLh4eHt+blP/5nW3y7uH1bj4eHh/dJXsvIt/s22G3/Wxy6wsPDw1vzZhP2TYSxGYANm3U8PDy8j/BmYWveXkeRa1wGijEYHh4e3iFe/oFTC8rv0A7knn5xeHh4eEd5bVjQhqr50atZSYhmenh4eHiXeZtx1KlAoV3h0/fg4eHhXea1Ye4G2S46b8fx8PDw7vF+yqsd5G8Wl0fDT1eFh4eHd4G3qieLEVoOOxUu4+Hh4Z3lzYpBHry2ce2+MODh4eF9hjebHLXt9SbqbY8a4OHh4X0nbx9JtOWnbq/x8PDwvpI328RnbXRdWvDw8PCu8c4eP53dOTp+WkYYeHh4eDd4sw095yXt8mYwduDCw8PDS3l/AKV0xTr7bVKkAAAAAElFTkSuQmCC" alt="微信分享二维码">
</div>




    <script src="//cdn.bootcss.com/node-waves/0.7.4/waves.min.js"></script>
<script>
var BLOG = { ROOT: '/', SHARE: true, REWARD: false };


</script>

<script src="/js/main.min.js?v=1.7.2"></script>


<div class="search-panel" id="search-panel">
    <ul class="search-result" id="search-result"></ul>
</div>
<template id="search-tpl">
<li class="item">
    <a href="{path}" class="waves-block waves-effect">
        <div class="title ellipsis" title="{title}">{title}</div>
        <div class="flex-row flex-middle">
            <div class="tags ellipsis">
                {tags}
            </div>
            <time class="flex-col time">{date}</time>
        </div>
    </a>
</li>
</template>

<script src="/js/search.min.js?v=1.7.2" async></script>










</body>
</html>

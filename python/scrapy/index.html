<!DOCTYPE html>
<html>
<head>
    

    

    



    <meta charset="utf-8">
    
    
    
    
    <title>Python 爬虫 —— Scrapy | 小灰灰灰灰的博客</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="theme-color" content="#3F51B5">
    
    
    <meta name="keywords" content="Python,爬虫">
    <meta name="description" content="原理                                                                                             爬虫原理               流程如下：  爬虫告诉引擎，需要爬取哪些链接 urls 引擎把链接发给调度器 调度器收到链接后，进入队列 调度器从队列里取出链接，告诉下载器开始下载 下载完毕后，把结果交给">
<meta property="og:type" content="article">
<meta property="og:title" content="Python 爬虫 —— Scrapy">
<meta property="og:url" content="https://blog.lyh543.cn/python/scrapy/index.html">
<meta property="og:site_name" content="小灰灰灰灰的博客">
<meta property="og:description" content="原理                                                                                             爬虫原理               流程如下：  爬虫告诉引擎，需要爬取哪些链接 urls 引擎把链接发给调度器 调度器收到链接后，进入队列 调度器从队列里取出链接，告诉下载器开始下载 下载完毕后，把结果交给">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://blog.lyh543.cn/images/28cf998153f11ab7a5b1579d5eccc122deb0ea3f8b1bf12c6fd177594f264039.png">
<meta property="og:image" content="https://blog.lyh543.cn/images/b1309aaf05e0ad49970483f90cb77c7617a5e269fb19144b6e8f24153b75939b.png">
<meta property="og:image" content="https://blog.lyh543.cn/images/31a4adde7ff3bd0d994afb68289034839baecd7b1b62ea959f5a33c4ecdccd0c.png">
<meta property="article:published_time" content="2020-07-01T07:41:43.000Z">
<meta property="article:modified_time" content="2021-09-11T12:19:35.171Z">
<meta property="article:author" content="lyh543">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="爬虫">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://blog.lyh543.cn/images/28cf998153f11ab7a5b1579d5eccc122deb0ea3f8b1bf12c6fd177594f264039.png">
    
        <link rel="alternate" type="application/atom+xml" title="小灰灰灰灰的博客" href="/atom.xml">
    
    <link rel="shortcut icon" href="/img/favicon.png">
    <link rel="stylesheet" href="/css/style.css?v=1.7.2">
    <script>window.lazyScripts=[]</script>

    <!-- custom head -->
    

<meta name="generator" content="Hexo 4.2.1"></head>

<body>
    <div id="loading" class="active"></div>

    <aside id="menu"  >
  <div class="inner flex-row-vertical">
    <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-off">
        <i class="mdi mdi-close icon-lg"></i>
    </a>
    <div class="brand-wrap" style="background-image:url(/img/brand.jpg)">
      <div class="brand">
        <a href="/" class="avatar waves-effect waves-circle waves-light">
          <img src="/img/avatar.png">
        </a>
        <hgroup class="introduce">
          <h5 class="nickname">lyh543</h5>
          <a href="mailto:lyh543@outlook.com" title="lyh543@outlook.com" class="mail">lyh543@outlook.com</a>
        </hgroup>
      </div>
    </div>
    <div class="scroll-wrap flex-col">
      <ul class="nav">
        
            <li class="waves-block waves-effect">
              <a href="/"  >
                <i class="icon icon-lg mdi mdi-home"></i>
                主页
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/archives"  >
                <i class="icon icon-lg mdi mdi-archive"></i>
                归档
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/tags"  >
                <i class="icon icon-lg mdi mdi-tag-multiple"></i>
                标签
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/categories"  >
                <i class="icon icon-lg mdi mdi-format-list-bulleted-square"></i>
                分类
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="https://github.com/lyh543" target="_blank" >
                <i class="icon icon-lg mdi mdi-github"></i>
                Github
              </a>
            </li>
        
      </ul>
    </div>
  </div>
</aside>

    <main id="main">
        <header class="top-header" id="header">
    <div class="flex-row">
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle">
          <i class="icon icon-lg mdi mdi-menu"></i>
        </a>
        <div class="flex-col header-title ellipsis">Python 爬虫 —— Scrapy</div>
        
        <div class="search-wrap" id="search-wrap">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
                <i class="icon icon-lg mdi mdi-chevron-left"></i>
            </a>
            <input type="text" id="key" class="search-input" autocomplete="off" placeholder="输入感兴趣的关键字">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="search">
                <i class="icon icon-lg mdi mdi-magnify"></i>
            </a>
        </div>
        
        
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menuShare">
            <i class="icon icon-lg mdi mdi-share-variant"></i>
        </a>
        
    </div>
</header>
<header class="content-header post-header">

    <div class="container fade-scale">
        <h1 class="title">Python 爬虫 —— Scrapy</h1>
        <h5 class="subtitle">
            
                <time datetime="2020-07-01T07:41:43.000Z" itemprop="datePublished" class="page-time">
  2020-07-01
</time>


	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/Python/">Python</a></li></ul>

            
        </h5>
    </div>

    


</header>


<div class="container body-wrap">
    
    <aside class="post-widget">
        <nav class="post-toc-wrap post-toc-shrink" id="post-toc">
            <h4>TOC</h4>
            <ol class="post-toc"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#原理"><span class="post-toc-text">原理</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#准备工作"><span class="post-toc-text">准备工作</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#简单爬虫"><span class="post-toc-text">简单爬虫</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#建立目录"><span class="post-toc-text">建立目录</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#生成爬虫代码"><span class="post-toc-text">生成爬虫代码</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#定义数据结构"><span class="post-toc-text">定义数据结构</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#解析网站"><span class="post-toc-text">解析网站</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#编写解析函数"><span class="post-toc-text">编写解析函数</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#编写管道"><span class="post-toc-text">编写管道</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#运行爬虫"><span class="post-toc-text">运行爬虫</span></a></li></ol></li></ol>
        </nav>
    </aside>


<article id="post-python/scrapy"
  class="post-article article-type-post fade" itemprop="blogPost">

    <div class="post-card">
        <h1 class="post-card-title">Python 爬虫 —— Scrapy</h1>
        <div class="post-meta">
            <time class="post-time" title="2020-07-01 15:41:43" datetime="2020-07-01T07:41:43.000Z"  itemprop="datePublished">2020-07-01</time>

            
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/Python/">Python</a></li></ul>



            

        </div>
        <div class="post-content" id="post-content" itemprop="postContent">
            <h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/images/28cf998153f11ab7a5b1579d5eccc122deb0ea3f8b1bf12c6fd177594f264039.png" alt="爬虫原理" title="">
                </div>
                <div class="image-caption">爬虫原理</div>
            </figure>

<p>流程如下：</p>
<ul>
<li><strong>爬虫</strong>告诉<strong>引擎</strong>，需要爬取哪些链接 <code>urls</code></li>
<li>引擎把链接发给<strong>调度器</strong></li>
<li>调度器收到链接后，进入<strong>队列</strong></li>
<li>调度器从队列里取出链接，告诉<strong>下载器</strong>开始下载</li>
<li>下载完毕后，把结果交给爬虫</li>
<li>爬虫把结果中取回数据，交给<strong>管道</strong></li>
<li>管道将数据存储到 MySQL/文本文件等</li>
</ul>
<h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><p>安装 Python 3 后，</p>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 <span class="keyword">install</span> scrapy</span><br></pre></td></tr></table></figure>

<p>（可选）在本地安装 Redis 数据库，端口 <code>5376</code>，用户名 <code>root</code>，密码 <code>123456</code>；然后安装 Python 调用 Redis 的库：</p>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 <span class="keyword">install</span> redis</span><br></pre></td></tr></table></figure>

<h2 id="简单爬虫"><a href="#简单爬虫" class="headerlink" title="简单爬虫"></a>简单爬虫</h2><p>这里针对一个列表的网页爬取其列表内容，示例为 <a href="https://mobile.ithome.com/" target="_blank" rel="noopener">https://mobile.ithome.com/</a> 的新闻标题、链接等信息。</p>
<h3 id="建立目录"><a href="#建立目录" class="headerlink" title="建立目录"></a>建立目录</h3><p>第一步，建立项目。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject my_spider D:\  <span class="comment"># 建立项目</span></span><br></pre></td></tr></table></figure>

<p>会建立如下目录：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">my_spider/</span><br><span class="line">    scrapy.cfg</span><br><span class="line">    my_spider/</span><br><span class="line">        __init__.py</span><br><span class="line">        items.py</span><br><span class="line">        pipelines.py</span><br><span class="line">        settings.py</span><br><span class="line">        spiders/</span><br><span class="line">            __init__.py</span><br><span class="line">            ...</span><br></pre></td></tr></table></figure>

<p>然后可以在 PyCharm 中打开 <code>D:\my_spider</code>。</p>
<p>其中，<code>settings.py</code> 中 <code>ROBOTSTXT_OBEY = True</code> 表示会自觉遵守页面规定，如果不让爬虫则不会进行爬虫。</p>
<h3 id="生成爬虫代码"><a href="#生成爬虫代码" class="headerlink" title="生成爬虫代码"></a>生成爬虫代码</h3><p>第二步，切换目录，然后生成一个爬虫：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /d D:\my_spider</span><br><span class="line">scrapy genspider ithome mobile.ithome.com <span class="comment"># 生成爬虫</span></span><br></pre></td></tr></table></figure>

<p>此时 <code>D:\my_spider\my_spider\spiders</code> 下会自动生成 <code>ithome.py</code>，内容如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">IthomeSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'ithome'</span></span><br><span class="line">    allowed_domains = [<span class="string">'mobile.ithome.com'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://mobile.ithome.com/'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span> <span class="comment"># 解析 (parse) 网页的方法</span></span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<p>这里可以将 <code>start_urls</code> 链接改为 <code>https</code>。</p>
<h3 id="定义数据结构"><a href="#定义数据结构" class="headerlink" title="定义数据结构"></a>定义数据结构</h3><p>第三步，定义数据结构。这里没有直接使用 Python 原生的继承于 <code>object</code> 的 <code>class</code>，而是选择继承 <code>scrapy.Item</code> 的类。这样定义的数据结构，更方便 Scrapy 处理。定义放在 <code>D:\my_spider\my_spider\items.py</code>。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">IthomeData</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        title = scrapy.Field()</span><br><span class="line">        time = scrapy.Field()</span><br><span class="line">        abstract = scrapy.Field()</span><br><span class="line">        url = scrapy.Field()</span><br></pre></td></tr></table></figure>

<h3 id="解析网站"><a href="#解析网站" class="headerlink" title="解析网站"></a>解析网站</h3><p>第四步，定义数据结构后，开始解析爬虫获得的数据。爬虫本质获得的是 <code>start_urls</code> 对应的 html 文件， 然后解析 html，将解析到的数据进行处理。</p>
<p>我们用 Chrome 打开 <a href="https://mobile.ithome.com/%EF%BC%8C%E5%8F%B3%E9%94%AE%E4%B8%80%E4%B8%AA%E6%A0%87%E9%A2%98%E5%B9%B6%E2%80%9C%E6%A3%80%E6%9F%A5%E2%80%9D%EF%BC%8C%E5%8F%AF%E4%BB%A5%E7%9C%8B%E5%88%B0%E8%AF%A5" target="_blank" rel="noopener">https://mobile.ithome.com/，右键一个标题并“检查”，可以看到该</a> HTML 的结构。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/images/b1309aaf05e0ad49970483f90cb77c7617a5e269fb19144b6e8f24153b75939b.png" alt="mobile.ithome.com 详情" title="">
                </div>
                <div class="image-caption">mobile.ithome.com 详情</div>
            </figure>

<p>同时，在命令行执行 <code>scrapy shell https://mobile.ithome.com/</code>。看到以下输出：</p>
<figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2020</span><span class="number">-07</span><span class="number">-01</span> <span class="number">16</span>:<span class="number">55</span>:<span class="number">01</span> [scrapy.core.engine] DEBUG: Crawled (<span class="number">200</span>) &lt;GET https:<span class="comment">//mobile.ithome.com/&gt; (referer: None)</span></span><br><span class="line"><span class="number">2020</span><span class="number">-07</span><span class="number">-01</span> <span class="number">16</span>:<span class="number">55</span>:<span class="number">02</span> [asyncio] DEBUG: Using proactor: IocpProactor</span><br><span class="line">[s] Available Scrapy objects:</span><br><span class="line">[s]   scrapy     scrapy module (contains scrapy.Request, scrapy.Selector, etc)</span><br><span class="line">[s]   crawler    &lt;scrapy.crawler.Crawler object at <span class="number">0x000001AEBC19F0A0</span>&gt;</span><br><span class="line">[s]   item       &#123;&#125;</span><br><span class="line">[s]   request    &lt;GET https:<span class="comment">//mobile.ithome.com/&gt;</span></span><br><span class="line">[s]   response   &lt;<span class="number">200</span> https:<span class="comment">//mobile.ithome.com/&gt;</span></span><br><span class="line">[s]   settings   &lt;scrapy.settings.Settings object at <span class="number">0x000001AEBC19BC70</span>&gt;</span><br><span class="line">[s]   spider     &lt;DefaultSpider <span class="string">'default'</span> at <span class="number">0x1aebc4e6730</span>&gt;</span><br><span class="line">[s] Useful shortcuts:</span><br><span class="line">[s]   fetch(url[, redirect=True]) Fetch URL <span class="keyword">and</span> update local objects (by <span class="keyword">default</span>, redirects are followed)</span><br><span class="line">[s]   fetch(req)                  Fetch a scrapy.Request <span class="keyword">and</span> update local objects</span><br><span class="line">[s]   shelp()           Shell help (print <span class="keyword">this</span> help)</span><br><span class="line">[s]   view(response)    View response <span class="keyword">in</span> a browser</span><br><span class="line"><span class="number">2020</span><span class="number">-07</span><span class="number">-01</span> <span class="number">16</span>:<span class="number">55</span>:<span class="number">02</span> [asyncio] DEBUG: Using proactor: IocpProactor</span><br><span class="line">In [<span class="number">1</span>]:</span><br></pre></td></tr></table></figure>

<p><code>200</code> 表示正常。输入 <code>response</code> 并回车：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">1</span>]: response</span><br><span class="line">Out[<span class="number">1</span>]: &lt;<span class="number">200</span> https://mobile.ithome.com/&gt;</span><br></pre></td></tr></table></figure>

<p>接下来解析 <code>response</code>。解析的方法是使用 <code>xpath</code>。</p>
<blockquote>
<p><code>XPath</code> 即为 XML 路径语言，它是一种用来确定 XML 文档中某部分位置的计算机语言。XPath 基于 XML 的树状结构，提供在数据结构树中找寻节点的能力。</p>
</blockquote>
<p>在 Chrome 中右键想要爬取的第一个标题，然后 Copy Xpath，如下图：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/images/31a4adde7ff3bd0d994afb68289034839baecd7b1b62ea959f5a33c4ecdccd0c.png" alt="获取 Xpath" title="">
                </div>
                <div class="image-caption">获取 Xpath</div>
            </figure>

<p>然后作为 <code>response</code> 的 <code>xpath</code> 成员函数的参数，执行，结果如下，如果输出不是 <code>[]</code> 则正确。使用 <code>extract_first</code> 看到其内容。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">12</span>]: response.xpath(<span class="string">'//*[@id="wrapper"]/div[1]/div[3]/ul[1]/li[1]/div/h2/a'</span>)</span><br><span class="line">Out[<span class="number">12</span>]: [&lt;Selector xpath=<span class="string">'//*[@id="wrapper"]/div[1]/div[3]/ul[1]/li[1]/div/h2/a'</span> data=<span class="string">'&lt;a href="https://www.ithome.com/0/491...'</span>&gt;]</span><br><span class="line"></span><br><span class="line">In [<span class="number">14</span>]: response.xpath(<span class="string">'//*[@id="wrapper"]/div[1]/div[3]/ul[1]/li[1]/div/h2/a'</span>).extract_first()</span><br><span class="line">Out[<span class="number">14</span>]: <span class="string">'&lt;a href="https://www.ithome.com/0/491/113.htm" target="_blank"&gt;小米NFC碰碰贴要回来了？小米高管：大家喜欢的话我们就做&lt;/a&gt;'</span></span><br></pre></td></tr></table></figure>

<p>可以看到，标题已经出来了，并且和前面的图是一致的。</p>
<p>然后尝试找到遍历的方法。html 里，<code>ul</code> 是列表（<code>unordered list</code>），下面的每一个元素为 <code>li</code>（<code>list item</code>）。将上面的 Xpath 从 <code>li</code> 分开，因为我们需要在 Python 中遍历每个元素。注意在 Xpath 中下标从 1 开始，而在 Python 中下标从 0 开始。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">16</span>]: response.xpath(<span class="string">'//*[@id="wrapper"]/div[1]/div[3]/ul[1]/li'</span>)[<span class="number">0</span>].xpath(<span class="string">'./div/h2/a'</span>).extract_first() <span class="comment"># 注意第二个 Xpath 的开头有个 .</span></span><br><span class="line">Out[<span class="number">16</span>]: <span class="string">'&lt;a href="https://www.ithome.com/0/491/113.htm" target="_blank"&gt;小米NFC碰碰贴要回来了？小米高管：大家喜欢的话我们就做&lt;/a&gt;'</span></span><br><span class="line">In [<span class="number">17</span>]: response.xpath(<span class="string">'//*[@id="wrapper"]/div[1]/div[3]/ul[1]/li'</span>)[<span class="number">1</span>].xpath(<span class="string">'./div/h2/a'</span>).extract_first() <span class="comment"># 测试下一篇文章是否也是对应的</span></span><br><span class="line">Out[<span class="number">17</span>]: <span class="string">'&lt;a href="https://www.ithome.com/0/491/111.htm" target="_blank"&gt;荣耀30系列强势霸榜618，蝉联多日销量冠军，立减300仅要2699起&lt;/a&gt;'</span></span><br></pre></td></tr></table></figure>

<p>再进一步获取其文本和链接，使用 <code>text()</code> 函数和 <code>@href</code>：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">18</span>]: response.xpath(<span class="string">'//*[@id="wrapper"]/div[1]/div[3]/ul[1]/li'</span>)[<span class="number">0</span>].xpath(<span class="string">'./div/h2/a/text()'</span>).extract_first()</span><br><span class="line">Out[<span class="number">18</span>]: <span class="string">'小米NFC碰碰贴要回来了？小米高管：大家喜欢的话我们就做'</span></span><br><span class="line">In [<span class="number">36</span>]: response.xpath(<span class="string">'//*[@id="wrapper"]/div[1]/div[3]/ul[1]/li'</span>)[<span class="number">0</span>].xpath(<span class="string">'./div/h2/a/@href'</span>).extract_first()</span><br><span class="line">Out[<span class="number">36</span>]: <span class="string">'https://www.ithome.com/0/491/113.htm'</span></span><br></pre></td></tr></table></figure>

<p>用同样的方法可以获取其时间、摘要：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">41</span>]: response.xpath(<span class="string">'//*[@id="wrapper"]/div[1]/div[3]/ul[1]/li'</span>)[<span class="number">0</span>].xpath(<span class="string">'./div/div/p'</span>).extract_first()</span><br><span class="line">Out[<span class="number">41</span>]: <span class="string">'&lt;p&gt;小米早前曾发布了一款名为“小米NFC碰碰贴”的产品。今日小米集团智能硬件部总经理刘新宇表示，当时碰碰贴概念太超前，如今大家喜欢，“那我们就做新版碰碰贴”。似乎也在暗示小米NFC碰碰贴产品即将回归&lt;/p&gt;'</span></span><br><span class="line">In [<span class="number">48</span>]: response.xpath(<span class="string">'//*[@id="wrapper"]/div[1]/div[3]/ul[1]/li'</span>)[<span class="number">0</span>].xpath(<span class="string">'./div/h2/span/text()'</span>).extract_first()</span><br><span class="line">Out[<span class="number">48</span>]: <span class="string">'今日 17:35'</span></span><br></pre></td></tr></table></figure>

<p>到这里就已经成功一半了。</p>
<h3 id="编写解析函数"><a href="#编写解析函数" class="headerlink" title="编写解析函数"></a>编写解析函数</h3><blockquote>
<p><code>parse()</code> 是 <code>spider</code> 的一个方法。 被调用时，每个初始 URL 完成下载后生成的 <code>Response</code> 对象将会作为唯一的参数传递给该函数。 该方法负责解析返回的数据(<code>response data</code>)，提取数据(生成<code>item</code>)以及生成需要进一步处理的 URL 的 <code>Request</code> 对象。</p>
</blockquote>
<p>回到 <code>D:\my_spider\my_spider\spiders\ithome.py</code>，编写 <code>parse</code> 成员函数。<code>parse</code> 函数的思想就是，遍历 <code>ul</code> 的 <code>li</code>，取出我们需要的信息存进 <code>item</code>，然后返回 <code>item</code>。这里直接上代码。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ithome.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> my_spider.items <span class="keyword">import</span> IthomeData</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">IthomeSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'ithome'</span></span><br><span class="line">    allowed_domains = [<span class="string">'mobile.ithome.com'</span>]</span><br><span class="line">    start_urls = [<span class="string">'https://mobile.ithome.com/'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        li_list = response.xpath(<span class="string">'//*[@id="wrapper"]/div[1]/div[3]/ul[1]/li'</span>)</span><br><span class="line">        item_list = []</span><br><span class="line">        <span class="keyword">for</span> li <span class="keyword">in</span> li_list:</span><br><span class="line">            item = IthomeData()</span><br><span class="line">            item[<span class="string">"title"</span>] = li.xpath(<span class="string">'./div/h2/a/text()'</span>).extract_first()</span><br><span class="line">            item[<span class="string">"url"</span>] = li.xpath(<span class="string">'./div/h2/a/@href'</span>).extract_first()</span><br><span class="line">            item[<span class="string">"abstract"</span>] = li.xpath(<span class="string">'./div/div/p'</span>).extract_first()</span><br><span class="line">            item[<span class="string">"time"</span>] = li.xpath(<span class="string">'./div/h2/span/text()'</span>).extract_first()</span><br><span class="line">            item_list.append(item)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> item_list</span><br></pre></td></tr></table></figure>

<p>注意，<code>import</code> 引入 <code>item</code> 的方式有点不一样，这里是 <code>from my_spider.items import IthomeData</code>。</p>
<h3 id="编写管道"><a href="#编写管道" class="headerlink" title="编写管道"></a>编写管道</h3><p>管道则是将上面 <code>parse</code> 函数的解析出来的 <code>item_list</code> 进行处理、存储。这里为简化代码，直接输出；当然也可以写入文本文件、存储到数据库等。代码如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pipelines.py</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MySpiderPipeline</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        print(item)</span><br></pre></td></tr></table></figure>

<h3 id="运行爬虫"><a href="#运行爬虫" class="headerlink" title="运行爬虫"></a>运行爬虫</h3><p>最后的最后，运行爬虫。可以直接在 <code>D:\my_spider\my_spider</code> 目录下运行 <code>scrapy crawl ithome</code>，也可以在该目录下编写以下 <code>python</code> 代码并运行。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy.cmdline <span class="keyword">import</span> execute</span><br><span class="line"></span><br><span class="line">execute(<span class="string">'scrapy crawl ithome'</span>.split(<span class="string">' '</span>))</span><br></pre></td></tr></table></figure>

<p>如果部分输出如下则正常（IT 之家貌似爬虫和直接访问得到的 HTML 不一样？可能做了防爬虫。至少方法是对的）。</p>
<figure class="highlight coffeescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">'abstract'</span>: <span class="string">'&lt;p&gt;今天小米10 Pro手机正式推送MIUI 12.0.1稳定版更新，并且不是稳定版内测，这意味着小米10 '</span></span><br><span class="line">             <span class="string">'Pro手机普通用户也可以方便升级MIUI 12.0.1稳定版系统了。&lt;/p&gt;'</span>,</span><br><span class="line"> <span class="string">'time'</span>: <span class="string">'今日 23:09'</span>,</span><br><span class="line"> <span class="string">'title'</span>: <span class="string">'小米 10 Pro 正式推送 MIUI 12 稳定版'</span>,</span><br><span class="line"> <span class="string">'url'</span>: <span class="string">'https://www.ithome.com/0/493/559.htm'</span>&#125;</span><br><span class="line"><span class="number">2020</span><span class="number">-07</span><span class="number">-01</span> <span class="number">18</span>:<span class="number">20</span>:<span class="number">38</span> [scrapy.core.scraper] DEBUG: Scraped <span class="keyword">from</span> &lt;<span class="number">200</span> https:<span class="regexp">//mobile.ithome.com/</span>&gt;</span><br><span class="line">&#123;<span class="string">'abstract'</span>: <span class="string">'&lt;p&gt;今日消息人士Jon_Prosser也曝光了代号为C68的苹果AirPower充电板原型机的真机照：此次曝光的AirPower充电板似乎解决了</span></span><br><span class="line"><span class="string">过热问题，其已可满足AirPods '</span></span><br><span class="line">             <span class="string">'Pro和一块Apple Watch同时充电&lt;/p&gt;'</span>,</span><br><span class="line"> <span class="string">'time'</span>: <span class="string">'今日 22:37'</span>,</span><br><span class="line"> <span class="string">'title'</span>: <span class="string">'苹果AirPower充电板原型机曝光！Apple Watch/AirPods可一起充电'</span>,</span><br><span class="line"> <span class="string">'url'</span>: <span class="string">'https://www.ithome.com/0/493/555.htm'</span>&#125;</span><br></pre></td></tr></table></figure>


        </div>

        <blockquote class="post-copyright">
    
    <div class="content">
        
<span class="post-time">
    最后更新时间：<time datetime="2021-09-11T12:19:35.171Z" itemprop="dateUpdated">2021-09-11 20:19:35</time>
</span><br>


        
    </div>
    
    <footer>
        <a href="https://blog.lyh543.cn">
            <img src="/img/avatar.png" alt="lyh543">
            lyh543
        </a>
    </footer>
</blockquote>

        


        <div class="post-footer">
            
	<ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Python/" rel="tag">Python</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%88%AC%E8%99%AB/" rel="tag">爬虫</a></li></ul>


            
<div class="page-share-wrap">
    

<div class="page-share" id="pageShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=https://blog.lyh543.cn/python/scrapy/&title=《Python 爬虫 —— Scrapy》 — 小灰灰灰灰的博客&pic=https://blog.lyh543.cn/img/avatar.png" data-title="微博">
          <i class="icon mdi mdi-sina-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=https://blog.lyh543.cn/python/scrapy/&title=《Python 爬虫 —— Scrapy》 — 小灰灰灰灰的博客&source=" data-title=" QQ">
          <i class="icon mdi mdi-qqchat"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=https://blog.lyh543.cn/python/scrapy/" data-title=" Facebook">
          <i class="icon mdi mdi-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《Python 爬虫 —— Scrapy》 — 小灰灰灰灰的博客&url=https://blog.lyh543.cn/python/scrapy/&via=https://blog.lyh543.cn" data-title=" Twitter">
          <i class="icon mdi mdi-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=https://blog.lyh543.cn/python/scrapy/" data-title=" Google+">
          <i class="icon mdi mdi-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>



    <a href="javascript:;" id="shareFab" class="page-share-fab waves-effect waves-circle">
        <i class="icon icon-lg mdi mdi-share-variant"></i>
    </a>
</div>



        </div>
    </div>

    
<nav class="post-nav flex-row flex-justify-between">
  
    <div class="waves-block waves-effect prev">
      <a href="/computer-science/big-data-learning-diary/" id="post-prev" class="post-nav-link">
        <div class="tips"><i class="icon mdi mdi-chevron-left icon-lg icon-pr"></i> Prev</div>
        <h4 class="title">华迪大数据专业实习日记</h4>
      </a>
    </div>
  

  
    <div class="waves-block waves-effect next">
      <a href="/linux/caddy/" id="post-next" class="post-nav-link">
        <div class="tips">Next <i class="icon icon-lg icon-pl mdi mdi-chevron-right"></i></div>
        <h4 class="title">Caddy 2</h4>
      </a>
    </div>
  
</nav>



    

















<section class="comments" id="comments">
    <div id="gitalk-container"></div>
    <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
    <script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
    <script>
        var id = location.pathname
        if (location.pathname.length > 50) {
          id = location.pathname.replace(/\/\d+\/\d+\/\d+\//, '').replace('/', '').substring(0, 50)
        }
        const gitalk = new Gitalk({
          clientID: 'ec7daa4e047c3c30570d',
          clientSecret: '025a9e40a1d101f28fd1a945d286a819e9fa1c3d',
          repo: 'lyh543.github.io',
          owner: 'lyh543',
          admin: ['lyh543'],
          id: id,      // Ensure uniqueness and length less than 50
          title: document.title.split('|')[0],
          distractionFreeMode: false  // Facebook-like distraction free mode
        })

        gitalk.render('gitalk-container')
    </script>
</section>




</article>



</div>

        <footer class="footer">
    <div class="top">
        

        <p>
            
                <span><a href="/atom.xml" target="_blank" class="rss" title="rss"><i class="icon icon-lg mdi mdi-rss"></i></a></span>
            
            <span>博客内容遵循 <a rel="license noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank">知识共享 署名 - 非商业性 - 相同方式共享 4.0 国际协议</a></span>
        </p>
    </div>
    <div class="bottom">
        <p><span>lyh543 &copy; 2019 - 2021</span>
            <span>
                
                <a href="http://www.miitbeian.gov.cn/" target="_blank">蜀ICP备19034464号</a><br>
                
                Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> Theme <a href="https://github.com/yscoder/hexo-theme-indigo" target="_blank">indigo</a>
            </span>
        </p>
    </div>
</footer>

    </main>
    <div class="mask" id="mask"></div>
<a href="javascript:;" id="gotop" class="waves-effect waves-circle waves-light"><span class="icon icon-lg mdi mdi-chevron-up"></span></a>



<div class="global-share" id="globalShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=https://blog.lyh543.cn/python/scrapy/&title=《Python 爬虫 —— Scrapy》 — 小灰灰灰灰的博客&pic=https://blog.lyh543.cn/img/avatar.png" data-title="微博">
          <i class="icon mdi mdi-sina-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=https://blog.lyh543.cn/python/scrapy/&title=《Python 爬虫 —— Scrapy》 — 小灰灰灰灰的博客&source=" data-title=" QQ">
          <i class="icon mdi mdi-qqchat"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=https://blog.lyh543.cn/python/scrapy/" data-title=" Facebook">
          <i class="icon mdi mdi-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《Python 爬虫 —— Scrapy》 — 小灰灰灰灰的博客&url=https://blog.lyh543.cn/python/scrapy/&via=https://blog.lyh543.cn" data-title=" Twitter">
          <i class="icon mdi mdi-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=https://blog.lyh543.cn/python/scrapy/" data-title=" Google+">
          <i class="icon mdi mdi-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>


<div class="page-modal wx-share" id="wxShare">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <p>扫一扫，分享到微信</p>
    <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAK4AAACuCAAAAACKZ2kyAAABwklEQVR42u3aOY7DMAwFUN//0hlgqgBBnE9RIlw8VUbi5akhuOi64vX6X+/X77983pnfc51YuLi4be7rdn1yv23jGyW/vjfg4uLOc/Pg9Y14/2x+/cOGi4v7MO59gpJvqRMocXFxn8atJkBJ/YKLi/tkbgJKVjXwHazVcHFxG9y1hune6+P9XVxc3E1TiTxIrSUx5a/j4uKOcJN2Z3VwUh3EVsshXFzcSW7nFUnRcp/Q5GMbXFzc09z8uFX/uEYS2n4EVlxc3BHu2kg12Vj1MFYeEHFxcee51WCUp0Rrg5MoL8PFxd3KPdcqXRvPFIIXLi7uCHdtCNrZWLVdi4uLO8Ptj1XWCpg89dk8BcLFxQ241ZZHtZipFkg/voWLizvOzROUXVsqF1S4uLgj3GooScqYJKFZS3pwcXFnuNUP3Ae1PLmpDmBwcXHnuVd7rR3wyt+Mi4s7z62OWtcGJHnLtfAALi7uAe6uULWtJRr/i4uLe5pbPZKVFz9rY9rCmRFcXNzD3E5J02mnlr+Li4v7MO4JaPnNuLi4j+T2B65rYxVcXNx57tqLqkev8u1taIvg4uI2uJ2GaX648/SGcXFxN3H/ALpU5x72LtE7AAAAAElFTkSuQmCC" alt="微信分享二维码">
</div>




    <script src="//cdn.bootcss.com/node-waves/0.7.4/waves.min.js"></script>
<script>
var BLOG = { ROOT: '/', SHARE: true, REWARD: false };


</script>

<script src="/js/main.min.js?v=1.7.2"></script>


<div class="search-panel" id="search-panel">
    <ul class="search-result" id="search-result"></ul>
</div>
<template id="search-tpl">
<li class="item">
    <a href="{path}" class="waves-block waves-effect">
        <div class="title ellipsis" title="{title}">{title}</div>
        <div class="flex-row flex-middle">
            <div class="tags ellipsis">
                {tags}
            </div>
            <time class="flex-col time">{date}</time>
        </div>
    </a>
</li>
</template>

<script src="/js/search.min.js?v=1.7.2" async></script>










</body>
</html>
